diff --git a/src/webrtc/build/common.gypi b/src/webrtc/build/common.gypi
index a8fdbcf..cff6493 100644
--- a/src/webrtc/build/common.gypi
+++ b/src/webrtc/build/common.gypi
@@ -42,6 +42,7 @@
       'modules_java_gyp_path%': '<(modules_java_gyp_path)',
       'gen_core_neon_offsets_gyp%': '<(gen_core_neon_offsets_gyp)',
       'webrtc_vp8_dir%': '<(webrtc_root)/modules/video_coding/codecs/vp8',
+      'webrtc_h264_dir%': '<(webrtc_root)/modules/video_coding/codecs/h264',      
       'rbe_components_path%': '<(webrtc_root)/modules/remote_bitrate_estimator',
       'include_opus%': 1,
     },
@@ -52,6 +53,7 @@
     'modules_java_gyp_path%': '<(modules_java_gyp_path)',
     'gen_core_neon_offsets_gyp%': '<(gen_core_neon_offsets_gyp)',
     'webrtc_vp8_dir%': '<(webrtc_vp8_dir)',
+    'webrtc_h264_dir%': '<(webrtc_h264_dir)',    
     'include_opus%': '<(include_opus)',
     'rbe_components_path%': '<(rbe_components_path)',
 
diff --git a/src/webrtc/common_types.h b/src/webrtc/common_types.h
index 5d63a61..2c08a9b 100644
--- a/src/webrtc/common_types.h
+++ b/src/webrtc/common_types.h
@@ -527,6 +527,13 @@ enum { kPayloadNameSize = 32};
 enum { kMaxSimulcastStreams = 4};
 enum { kMaxTemporalStreams = 4};
 
+// H.264 specific
+enum H264Packetization
+{
+    kH264SingleMode         = 0,
+    kH264NonInterleavedMode = 1
+};
+
 enum VideoCodecComplexity
 {
     kComplexityNormal = 0,
@@ -541,6 +548,22 @@ enum VideoCodecProfile
     kProfileMain = 0x01
 };
 
+struct VideoCodecH264
+{
+
+	      uint8_t        profile;
+	      uint8_t        constraints;
+	      uint8_t        level;
+	      uint8_t        packetizationMode; // 0 or 1
+	      bool           frameDroppingOn;
+	      int            keyFrameInterval;
+	      // These are null/0 if not externally negotiated
+	      const uint8_t* spsData;
+	      size_t         spsLen;
+	      const uint8_t* ppsData;
+	      size_t         ppsLen;
+};
+
 enum VP8ResilienceMode {
   kResilienceOff,    // The stream produced by the encoder requires a
                      // recovery frame (typically a key frame) to be
@@ -587,6 +610,7 @@ struct VideoCodecVP8 {
 enum VideoCodecType
 {
     kVideoCodecVP8,
+    kVideoCodecH264,
     kVideoCodecI420,
     kVideoCodecRED,
     kVideoCodecULPFEC,
@@ -596,7 +620,8 @@ enum VideoCodecType
 
 union VideoCodecUnion
 {
-    VideoCodecVP8       VP8;
+    VideoCodecH264      H264;
+	VideoCodecVP8       VP8;
 };
 
 
diff --git a/src/webrtc/engine_configurations.h b/src/webrtc/engine_configurations.h
index 0fb0949..c5db7bb 100644
--- a/src/webrtc/engine_configurations.h
+++ b/src/webrtc/engine_configurations.h
@@ -51,6 +51,7 @@
 
 #define VIDEOCODEC_I420
 #define VIDEOCODEC_VP8
+#define VIDEOCODEC_H264
 
 // ============================================================================
 //                                 VoiceEngine
diff --git a/src/webrtc/modules/interface/module_common_types.h b/src/webrtc/modules/interface/module_common_types.h
index 6c7ac10..fc1ab0f 100644
--- a/src/webrtc/modules/interface/module_common_types.h
+++ b/src/webrtc/modules/interface/module_common_types.h
@@ -75,13 +75,23 @@ struct RTPVideoHeaderVP8 {
   bool beginningOfPartition;  // True if this packet is the first
                               // in a VP8 partition. Otherwise false
 };
+
+// This is NOT carried in RTP
+struct RTPVideoHeaderH264
+{
+   uint8_t nalu_header;
+   bool    single_nalu;
+};
+
 union RTPVideoTypeHeader {
   RTPVideoHeaderVP8 VP8;
+  RTPVideoHeaderH264 H264;
 };
 
 enum RtpVideoCodecTypes {
   kRtpVideoNone,
   kRtpVideoGeneric,
+  kRtpVideoH264,
   kRtpVideoVp8
 };
 struct RTPVideoHeader {
@@ -876,6 +886,13 @@ inline bool IsNewerTimestamp(uint32_t timestamp, uint32_t prev_timestamp) {
          static_cast<uint32_t>(timestamp - prev_timestamp) < 0x80000000;
 }
 
+inline bool IsNewerOrSameTimestamp(uint32_t timestamp, uint32_t prev_timestamp)
+    {
+   return timestamp == prev_timestamp ||
+       static_cast<uint32_t>(timestamp - prev_timestamp) < 0x80000000;
+ }
+
+
 inline uint16_t LatestSequenceNumber(uint16_t sequence_number1,
                                      uint16_t sequence_number2) {
   return IsNewerSequenceNumber(sequence_number1, sequence_number2)
diff --git a/src/webrtc/modules/rtp_rtcp/source/rtp_format_h264.cc b/src/webrtc/modules/rtp_rtcp/source/rtp_format_h264.cc
new file mode 100644
index 0000000..359325c
--- /dev/null
+++ b/src/webrtc/modules/rtp_rtcp/source/rtp_format_h264.cc
@@ -0,0 +1,113 @@
+    /*
+     *  Copyright (c) 2014 The WebRTC project authors. All Rights Reserved.
+     *
+     *  Use of this source code is governed by a BSD-style license
+     *  that can be found in the LICENSE file in the root of the source
+     *  tree. An additional intellectual property rights grant can be found
+     *  in the file PATENTS.  All contributing project authors may
+     *  be found in the AUTHORS file in the root of the source tree.
+     */
+
+   #include <string.h>  // memcpy
+
+   #include "webrtc/modules/rtp_rtcp/source/rtp_format_h264.h"
+   #include "webrtc/system_wrappers/interface/trace.h"
+
+   namespace webrtc {
+
+   RtpFormatH264::RtpFormatH264(const uint8_t* payload_data,
+                                uint32_t payload_size,
+                                int max_payload_len)
+       : payload_data_(payload_data),
+         payload_size_(static_cast<int>(payload_size)),
+         max_payload_len_(static_cast<int>(max_payload_len)),
+         fragments_(0),
+         fragment_size_(0),
+         next_fragment_(-1) {
+     if (payload_size_ <= max_payload_len_) {
+       fragments_ = 0;
+     } else {
+       fragment_size_ = max_payload_len_ - kH264FUAHeaderLengthInBytes;
+       fragments_ = ((payload_size_ - kH264NALHeaderLengthInBytes) + (fragment_size_-1)) / fragment_size_;
+       next_fragment_ = 0;
+     }
+   }
+
+   RtpFormatH264::~RtpFormatH264() {
+   }
+
+   int RtpFormatH264::NextPacket(uint8_t* buffer,
+                                 int* bytes_to_send,
+                                 bool* last_packet) {
+     if (next_fragment_ == fragments_) {
+       *bytes_to_send = 0;
+       *last_packet   = true;
+       return -1;
+     }
+
+     // TODO(jesup) This supports Mode 1 packetization only
+
+     // For mode 0, it's all single-NAL, and maybe deal with that by simply
+     // setting a large max_payload_len when constructing this (and tell the
+     // codec to keep generated NAL sizes less than one packet).  If the codec
+     // goes over, a fragmented RTP packet would be sent (and may work or not).
+     uint8_t header = payload_data_[0];
+     uint8_t type   = header & kH264NAL_TypeMask;
+     if (payload_size_ <= max_payload_len_) {
+       // single NAL_UNIT
+       *bytes_to_send = payload_size_;
+       // TODO(jesup) - this doesn't work correctly for Mode 0.
+       // Unfortunately, we don't have a good signal to which NAL generated by
+       // the encoder is the last NAL of the frame.  We need that to be passed
+       // through to this point, instead of trying to generate it from the packets
+       if (type == kH264NALU_SPS || type == kH264NALU_PPS ||
+           type == kH264NALU_SEI) {
+         *last_packet   = false;
+       } else {
+         *last_packet   = true;
+       }
+       memcpy(buffer, payload_data_, payload_size_);
+       WEBRTC_TRACE(kTraceStream, kTraceRtpRtcp, -1,
+                    "RtpFormatH264(single NALU with type:%d, payload_size:%d",
+                    type, payload_size_);
+       return 0;
+     } else {
+       uint8_t fu_indicator = (header & (kH264NAL_FBit | kH264NAL_NRIMask)) |
+                              kH264NALU_FUA;
+       uint8_t fu_header = 0;
+       bool first_fragment = (next_fragment_ == 0);
+       bool last_fragment = (next_fragment_ == (fragments_ -1));
+
+       // S | E | R | 5 bit type.
+       fu_header |= (first_fragment ? kH264FU_SBit : 0);
+       fu_header |= (last_fragment ? kH264FU_EBit :0);
+       fu_header |= type;
+       buffer[0] = fu_indicator;
+       buffer[1] = fu_header;
+
+       if (last_fragment) {
+         // last fragment
+         *bytes_to_send = payload_size_ -
+                          kH264NALHeaderLengthInBytes -
+                          next_fragment_ * fragment_size_ +
+                          kH264FUAHeaderLengthInBytes;
+         *last_packet   = true;
+         memcpy(buffer + kH264FUAHeaderLengthInBytes,
+                payload_data_ + kH264NALHeaderLengthInBytes +
+                   next_fragment_ * fragment_size_,
+                *bytes_to_send - kH264FUAHeaderLengthInBytes);
+        // We do not send original NALU header
+      } else {
+        *bytes_to_send = fragment_size_ + kH264FUAHeaderLengthInBytes;
+        *last_packet   = false;
+        memcpy(buffer + kH264FUAHeaderLengthInBytes,
+               payload_data_ + kH264NALHeaderLengthInBytes +
+                   next_fragment_ * fragment_size_,
+               fragment_size_);  // We do not send original NALU header
+      }
+      next_fragment_++;
+      return 1;
+    }
+ }
+
+ }  // namespace webrtc
diff --git a/src/webrtc/modules/rtp_rtcp/source/rtp_format_h264.h b/src/webrtc/modules/rtp_rtcp/source/rtp_format_h264.h
new file mode 100644
index 0000000..e40a6de
--- /dev/null
+++ b/src/webrtc/modules/rtp_rtcp/source/rtp_format_h264.h
@@ -0,0 +1,96 @@
+/*
+ *  Copyright (c) 2011 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+/*
+ * This file contains the declaration of the H264 packetizer class.
+ * A packetizer object is created for each encoded video frame. The
+ * constructor is called with the payload data and size,
+ * together with the fragmentation information and a packetizer mode
+ * of choice. Alternatively, if no fragmentation info is available, the
+ * second constructor can be used with only payload data and size; in that
+ * case the mode kEqualSize is used.
+ *
+ * After creating the packetizer, the method NextPacket is called
+ * repeatedly to get all packets for the frame. The method returns
+ * false as long as there are more packets left to fetch.
+ */
+
+#ifndef WEBRTC_MODULES_RTP_RTCP_SOURCE_RTP_FORMAT_H264_H_
+#define WEBRTC_MODULES_RTP_RTCP_SOURCE_RTP_FORMAT_H264_H_
+
+#include "webrtc/modules/interface/module_common_types.h"
+#include "webrtc/system_wrappers/interface/constructor_magic.h"
+#include "webrtc/typedefs.h"
+
+namespace webrtc {
+
+// Packetizer for H264.
+class RtpFormatH264 {
+ public:
+ enum {
+     kH264NALU_SLICE             = 1,
+     kH264NALU_IDR               = 5,
+	 kH264NALU_SEI               = 6,
+	 kH264NALU_SPS               = 7,
+	 kH264NALU_PPS               = 8,
+	 kH264NALU_STAPA             = 24,
+	 kH264NALU_FUA               = 28
+  };
+  static const int kH264NALHeaderLengthInBytes = 1;
+  static const int kH264FUAHeaderLengthInBytes = 2;
+
+  // bits for FU (A and B) indicators
+  enum H264NalDefs {
+       kH264NAL_FBit = 0x80,
+       kH264NAL_NRIMask = 0x60,
+       kH264NAL_TypeMask = 0x1F
+  };
+
+  enum H264FUDefs {
+    // bits for FU (A and B) headers
+	  kH264FU_SBit = 0x80,
+	  kH264FU_EBit = 0x40,
+      kH264FU_RBit = 0x20
+   };
+  // Initialize with payload from encoder.
+  // The payload_data must be exactly one encoded H264 frame.
+  RtpFormatH264(const uint8_t* payload_data,
+               uint32_t payload_size,
+               int max_payload_len);
+
+  ~RtpFormatH264();
+
+  // Get the next payload with H264 payload header.
+  // max_payload_len limits the sum length of payload and H264 payload header.
+  // buffer is a pointer to where the output will be written.
+  // bytes_to_send is an output variable that will contain number of bytes
+  // written to buffer. Parameter last_packet is true for the last packet of
+  // the frame, false otherwise (i.e., call the function again to get the
+  // next packet).
+  // Returns 0 on success for single NAL_UNIT
+  // Returns 1 on success for fragmentation
+  // return -1 on error.
+  int NextPacket(uint8_t* buffer,
+                 int* bytes_to_send,
+                 bool* last_packet);
+
+ private:
+  const uint8_t* payload_data_;
+  const int payload_size_;
+  const int max_payload_len_;
+  int   fragments_;
+  int   fragment_size_;
+  int   next_fragment_;
+  DISALLOW_COPY_AND_ASSIGN(RtpFormatH264);
+};
+
+}  // namespace
+
+#endif  // WEBRTC_MODULES_RTP_RTCP_SOURCE_RTP_FORMAT_H264_H_
diff --git a/src/webrtc/modules/rtp_rtcp/source/rtp_payload_registry.cc b/src/webrtc/modules/rtp_rtcp/source/rtp_payload_registry.cc
index 1c3b990..9a5ae16 100644
--- a/src/webrtc/modules/rtp_rtcp/source/rtp_payload_registry.cc
+++ b/src/webrtc/modules/rtp_rtcp/source/rtp_payload_registry.cc
@@ -448,6 +448,8 @@ class RTPPayloadVideoStrategy : public RTPPayloadStrategy {
     RtpVideoCodecTypes videoType = kRtpVideoGeneric;
     if (ModuleRTPUtility::StringCompare(payloadName, "VP8", 3)) {
       videoType = kRtpVideoVp8;
+    } else if (ModuleRTPUtility::StringCompare(payloadName, "H264", 4)) {
+      videoType = kRtpVideoH264;
     } else if (ModuleRTPUtility::StringCompare(payloadName, "I420", 4)) {
       videoType = kRtpVideoGeneric;
     } else if (ModuleRTPUtility::StringCompare(payloadName, "ULPFEC", 6)) {
diff --git a/src/webrtc/modules/rtp_rtcp/source/rtp_receiver_video.cc b/src/webrtc/modules/rtp_rtcp/source/rtp_receiver_video.cc
index b733cdb..cc34e3e 100644
--- a/src/webrtc/modules/rtp_rtcp/source/rtp_receiver_video.cc
+++ b/src/webrtc/modules/rtp_rtcp/source/rtp_receiver_video.cc
@@ -19,6 +19,7 @@
 #include "webrtc/system_wrappers/interface/critical_section_wrapper.h"
 #include "webrtc/system_wrappers/interface/trace.h"
 #include "webrtc/system_wrappers/interface/trace_event.h"
+#include "webrtc/modules/rtp_rtcp/source/rtp_format_h264.h"
 
 namespace webrtc {
 
@@ -124,6 +125,8 @@ int32_t RTPReceiverVideo::ParseVideoCodecSpecific(
       return ReceiveGenericCodec(rtp_header, payload_data, payload_data_length);
     case kRtpVideoVp8:
       return ReceiveVp8Codec(rtp_header, payload_data, payload_data_length);
+    case kRtpVideoH264:
+      return ReceiveH264Codec(rtp_header, payload_data, payload_data_length);
     case kRtpVideoNone:
       break;
   }
@@ -220,6 +223,103 @@ int32_t RTPReceiverVideo::ReceiveVp8Codec(WebRtcRTPHeader* rtp_header,
   return 0;
 }
 
+int32_t RTPReceiverVideo::ReceiveH264Codec(WebRtcRTPHeader* rtp_header,
+                                          const uint8_t* payload_data,
+                                          uint16_t payload_data_length) {
+	// real payload
+	uint8_t* payload;
+	uint16_t payload_length;
+	uint8_t nal_type = payload_data[0] & RtpFormatH264::kH264NAL_TypeMask;
+
+	// Note: This code handles only FU-A and single NALU mode packets.
+	if (nal_type == RtpFormatH264::kH264NALU_FUA) {
+	     // Fragmentation
+	     uint8_t fnri = payload_data[0] &
+	                (RtpFormatH264::kH264NAL_FBit | RtpFormatH264::kH264NAL_NRIMask);
+	      uint8_t original_nal_type = payload_data[1] & RtpFormatH264::kH264NAL_TypeMask;
+	      bool first_fragment = !!(payload_data[1] & RtpFormatH264::kH264FU_SBit);
+	      //bool last_fragment = !!(payload_data[1] & RtpFormatH264::kH264FU_EBit);
+
+	      uint8_t original_nal_header = fnri | original_nal_type;
+	      if (first_fragment) {
+	        payload = const_cast<uint8_t*> (payload_data) +
+	            RtpFormatH264::kH264NALHeaderLengthInBytes;
+	        payload[0] = original_nal_header;
+	        payload_length = payload_data_length -
+	            RtpFormatH264::kH264NALHeaderLengthInBytes;
+	      } else {
+	        payload = const_cast<uint8_t*> (payload_data)  +
+	            RtpFormatH264::kH264FUAHeaderLengthInBytes;
+	        payload_length = payload_data_length -
+	            RtpFormatH264::kH264FUAHeaderLengthInBytes;
+	      }
+
+	      // WebRtcRTPHeader
+	      if (original_nal_type == RtpFormatH264::kH264NALU_IDR) {
+	        rtp_header->frameType = kVideoFrameKey;
+	      } else {
+	        rtp_header->frameType = kVideoFrameDelta;
+	      }
+	      rtp_header->type.Video.codec    = kRtpVideoH264;
+	      rtp_header->type.Video.isFirstPacket = first_fragment;
+	      RTPVideoHeaderH264* h264_header = &rtp_header->type.Video.codecHeader.H264;
+	      h264_header->nalu_header        = original_nal_header;
+	      h264_header->single_nalu        = false;
+
+	      WEBRTC_TRACE(kTraceStream,
+		               kTraceRtpRtcp,
+		               id_,
+		               "%s(timestamp:%u), nal_type is %u, nalu_header %x, not single",
+		               __FUNCTION__,
+		               rtp_header->header.timestamp, original_nal_type, h264_header->nalu_header);
+
+	    } else {
+	     // single NALU
+	      payload = const_cast<uint8_t*> (payload_data);
+	      payload_length = payload_data_length;
+
+	      rtp_header->type.Video.codec    = kRtpVideoH264;
+	      rtp_header->type.Video.isFirstPacket = true;
+	      RTPVideoHeaderH264* h264_header = &rtp_header->type.Video.codecHeader.H264;
+	      h264_header->nalu_header        = payload_data[0];
+	      h264_header->single_nalu        = true;
+
+	      // WebRtcRTPHeader
+	      switch (nal_type) {
+	        // TODO(jesup): Evil hack.  The jitter buffer *really* doesn't like
+	        // "frames" to have the same timestamps.  NOTE: this only works
+	        // for SPS/PPS/IDR, not for PPS/SPS/IDR.  Keep this until all issues
+	        // are resolved in the jitter buffer
+	        case RtpFormatH264::kH264NALU_SPS:
+	          rtp_header->header.timestamp -= 10;
+	          // fall through
+	        case RtpFormatH264::kH264NALU_PPS:
+	          rtp_header->header.timestamp -= 10;
+	        case RtpFormatH264::kH264NALU_IDR:
+	          rtp_header->frameType = kVideoFrameKey;
+	          break;
+	        default:
+	          rtp_header->frameType = kVideoFrameDelta;
+	          break;
+	      }
+		  WEBRTC_TRACE(kTraceStream,
+		               kTraceRtpRtcp,
+		               id_,
+		               "%s(timestamp:%u), nal_type is %u, nalu_header %x",
+		               __FUNCTION__,
+		               rtp_header->header.timestamp, nal_type, h264_header->nalu_header);
+
+    }
+
+
+  if (data_callback_->OnReceivedPayloadData(payload,
+                                            payload_length,
+                                            rtp_header) != 0) {
+    return -1;
+  }
+  return 0;
+}
+
 int32_t RTPReceiverVideo::ReceiveGenericCodec(
     WebRtcRTPHeader* rtp_header,
     const uint8_t* payload_data,
diff --git a/src/webrtc/modules/rtp_rtcp/source/rtp_receiver_video.h b/src/webrtc/modules/rtp_rtcp/source/rtp_receiver_video.h
index ab69b40..1e61af6 100644
--- a/src/webrtc/modules/rtp_rtcp/source/rtp_receiver_video.h
+++ b/src/webrtc/modules/rtp_rtcp/source/rtp_receiver_video.h
@@ -68,7 +68,9 @@ class RTPReceiverVideo : public RTPReceiverStrategy {
   int32_t ReceiveVp8Codec(WebRtcRTPHeader* rtp_header,
                           const uint8_t* payload_data,
                           uint16_t payload_data_length);
-
+  int32_t ReceiveH264Codec(WebRtcRTPHeader* rtp_header,
+                            const uint8_t* payload_data,
+                            uint16_t payload_data_length);
   int32_t BuildRTPheader(const WebRtcRTPHeader* rtp_header,
                          uint8_t* data_buffer) const;
 
diff --git a/src/webrtc/modules/rtp_rtcp/source/rtp_rtcp.gypi b/src/webrtc/modules/rtp_rtcp/source/rtp_rtcp.gypi
index 0a8c901..5ab1efb 100644
--- a/src/webrtc/modules/rtp_rtcp/source/rtp_rtcp.gypi
+++ b/src/webrtc/modules/rtp_rtcp/source/rtp_rtcp.gypi
@@ -86,6 +86,8 @@
         'video_codec_information.h',
         'rtp_format_vp8.cc',
         'rtp_format_vp8.h',
+        'rtp_format_h264.cc',
+        'rtp_format_h264.h',        
         'rtp_format_video_generic.h',
         'vp8_partition_aggregator.cc',
         'vp8_partition_aggregator.h',
diff --git a/src/webrtc/modules/rtp_rtcp/source/rtp_sender_video.cc b/src/webrtc/modules/rtp_rtcp/source/rtp_sender_video.cc
index 10bc252..6e8abe1 100644
--- a/src/webrtc/modules/rtp_rtcp/source/rtp_sender_video.cc
+++ b/src/webrtc/modules/rtp_rtcp/source/rtp_sender_video.cc
@@ -18,6 +18,7 @@
 #include "webrtc/modules/rtp_rtcp/source/producer_fec.h"
 #include "webrtc/modules/rtp_rtcp/source/rtp_format_video_generic.h"
 #include "webrtc/modules/rtp_rtcp/source/rtp_format_vp8.h"
+#include "webrtc/modules/rtp_rtcp/source/rtp_format_h264.h"
 #include "webrtc/modules/rtp_rtcp/source/rtp_utility.h"
 #include "webrtc/system_wrappers/interface/critical_section_wrapper.h"
 #include "webrtc/system_wrappers/interface/trace.h"
@@ -92,6 +93,8 @@ int32_t RTPSenderVideo::RegisterVideoPayload(
   RtpVideoCodecTypes videoType = kRtpVideoGeneric;
   if (ModuleRTPUtility::StringCompare(payloadName, "VP8",3)) {
     videoType = kRtpVideoVp8;
+  } else if (ModuleRTPUtility::StringCompare(payloadName, "H264", 4))  {
+    videoType = kRtpVideoH264;
   } else if (ModuleRTPUtility::StringCompare(payloadName, "I420", 4)) {
     videoType = kRtpVideoGeneric;
   } else {
@@ -321,6 +324,16 @@ RTPSenderVideo::SendVideo(const RtpVideoCodecTypes videoType,
                          fragmentation,
                          rtpTypeHdr);
         break;
+    case kRtpVideoH264:
+    	retVal = SendH264(frameType,
+    			payloadType,
+    			captureTimeStamp,
+    			capture_time_ms,
+    			payloadData,
+    			payloadSize,
+    			fragmentation,
+    			rtpTypeHdr);
+    	break;
     default:
         assert(false);
         break;
@@ -486,6 +499,61 @@ RTPSenderVideo::SendVP8(const FrameType frameType,
     return 0;
 }
 
+int32_t
+RTPSenderVideo::SendH264(const FrameType frameType,
+                        const int8_t payloadType,
+                        const uint32_t captureTimeStamp,
+                        int64_t capture_time_ms,
+                        const uint8_t* payloadData,
+                        const uint32_t payloadSize,
+                        const RTPFragmentationHeader* fragmentation,
+                        const RTPVideoTypeHeader* rtpTypeHdr) {
+
+    const uint16_t rtpHeaderLength = _rtpSender.RTPHeaderLength();
+
+    int32_t payloadBytesToSend = payloadSize;
+    const uint8_t* data = payloadData;
+
+    uint16_t maxPayloadLengthH264 = _rtpSender.MaxDataPayloadLength();
+
+    RtpFormatH264 packetizer(data, payloadBytesToSend, maxPayloadLengthH264);
+
+    StorageType storage = kAllowRetransmission;
+    bool protect = (frameType == kVideoFrameKey);
+    bool last = false;
+
+    while (!last)
+    {
+        // Write H264 Payload
+        uint8_t dataBuffer[IP_PACKET_SIZE] = {0};
+        int payloadBytesInPacket = 0;
+        int ret_val = packetizer.NextPacket(&dataBuffer[rtpHeaderLength],
+                                            &payloadBytesInPacket, &last);
+        if (ret_val < 0)
+        {
+            return -1;
+        }
+
+        // Write RTP header.
+        // Set marker bit true if this is the last packet in frame.
+        _rtpSender.BuildRTPheader(dataBuffer, payloadType, last,
+                                  captureTimeStamp, capture_time_ms);
+        if (-1 == SendVideoPacket(dataBuffer, payloadBytesInPacket,
+                                  rtpHeaderLength, captureTimeStamp,
+                                  capture_time_ms, storage, protect))
+        {
+          WEBRTC_TRACE(kTraceError, kTraceRtpRtcp, _id,
+                       "RTPSenderVideo::SendH264 failed to send packet number"
+                       " %d", _rtpSender.SequenceNumber());
+        }
+        if (ret_val == 0) {
+          // single NAL unit
+          last = true;
+        }
+    }
+    return 0;
+}
+
 void RTPSenderVideo::ProcessBitrate() {
   _videoBitrate.Process();
   _fecOverheadRate.Process();
diff --git a/src/webrtc/modules/rtp_rtcp/source/rtp_sender_video.h b/src/webrtc/modules/rtp_rtcp/source/rtp_sender_video.h
index 4c406d7..dbe2253 100644
--- a/src/webrtc/modules/rtp_rtcp/source/rtp_sender_video.h
+++ b/src/webrtc/modules/rtp_rtcp/source/rtp_sender_video.h
@@ -110,7 +110,14 @@ private:
                     const uint32_t payloadSize,
                     const RTPFragmentationHeader* fragmentation,
                     const RTPVideoTypeHeader* rtpTypeHdr);
-
+    int32_t SendH264(const FrameType frameType,
+    		const int8_t payloadType,
+    		const uint32_t captureTimeStamp,
+    		int64_t capture_time_ms,
+    		const uint8_t* payloadData,
+    		const uint32_t payloadSize,
+    		const RTPFragmentationHeader* fragmentation,
+    		const RTPVideoTypeHeader* rtpTypeHdr);
 private:
     int32_t             _id;
     RTPSenderInterface&        _rtpSender;
diff --git a/src/webrtc/modules/video_coding/codecs/h264/ffmpeg_h264_impl.cc b/src/webrtc/modules/video_coding/codecs/h264/ffmpeg_h264_impl.cc
new file mode 100644
index 0000000..ec3874e
--- /dev/null
+++ b/src/webrtc/modules/video_coding/codecs/h264/ffmpeg_h264_impl.cc
@@ -0,0 +1,530 @@
+/*
+ *  Copyright (c) 2012 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ *
+ * This file contains the WEBRTC H264 wrapper implementation
+ *
+ */
+
+#include "webrtc/modules/video_coding/codecs/h264/h264_impl.h"
+
+#include <stdlib.h>
+#include <string.h>
+#include <time.h>
+#include <vector>
+#include <climits>
+
+#include "webrtc/common.h"
+#include "webrtc/common_video/libyuv/include/webrtc_libyuv.h"
+#include "webrtc/modules/interface/module_common_types.h"
+#include "webrtc/system_wrappers/interface/trace.h"
+#include "webrtc/system_wrappers/interface/tick_util.h"
+#include "webrtc/system_wrappers/interface/trace_event.h"
+
+namespace webrtc {
+
+H264Encoder* H264Encoder::Create() {
+  return new H264EncoderImpl();
+}
+
+H264EncoderImpl::H264EncoderImpl()
+    : encoded_image_(),
+      encoded_complete_callback_(NULL),
+      inited_(false),
+      first_frame_encoded_(false),
+      timestamp_(0) {
+  memset(&codec_, 0, sizeof(codec_));
+  uint32_t seed = static_cast<uint32_t>(TickTime::MillisecondTimestamp());
+  srand(seed);
+
+  avcodec_register_all();
+  vCoder = NULL;
+  vCoderContext = NULL;
+  cPicture = NULL;
+
+}
+
+H264EncoderImpl::~H264EncoderImpl() {
+  Release();
+}
+
+int H264EncoderImpl::Release() {
+  if (encoded_image_._buffer != NULL) {
+    delete [] encoded_image_._buffer;
+    encoded_image_._buffer = NULL;
+  }
+
+  if (vCoderContext!=NULL)
+    avcodec_close(vCoderContext);
+  if (cPicture !=NULL)
+    avcodec_free_frame(&cPicture);
+
+  inited_ = false;
+  return WEBRTC_VIDEO_CODEC_OK;
+}
+
+int H264EncoderImpl::SetRates(uint32_t new_bitrate_kbit,
+                             uint32_t new_framerate) {
+  WEBRTC_TRACE(webrtc::kTraceApiCall, webrtc::kTraceVideoCoding, -1,
+               "H264EncoderImpl::SetRates(%d, %d)", new_bitrate_kbit, new_framerate);
+  if (!inited_) {
+    return WEBRTC_VIDEO_CODEC_UNINITIALIZED;
+  }
+  if (new_framerate < 1) {
+    return WEBRTC_VIDEO_CODEC_ERR_PARAMETER;
+  }
+  // update bit rate
+  if (codec_.maxBitrate > 0 && new_bitrate_kbit > codec_.maxBitrate) {
+    codec_.maxBitrate = new_bitrate_kbit ;
+  }
+
+  return WEBRTC_VIDEO_CODEC_OK;
+}
+
+int H264EncoderImpl::InitEncode(const VideoCodec* inst,
+                               int number_of_cores,
+                               uint32_t /*max_payload_size*/) {
+  if (inst == NULL) {
+    return WEBRTC_VIDEO_CODEC_ERR_PARAMETER;
+  }
+  if (inst->maxFramerate < 1) {
+    return WEBRTC_VIDEO_CODEC_ERR_PARAMETER;
+  }
+  // allow zero to represent an unspecified maxBitRate
+  if (inst->maxBitrate > 0 && inst->startBitrate > inst->maxBitrate) {
+    return WEBRTC_VIDEO_CODEC_ERR_PARAMETER;
+  }
+  if (inst->width < 1 || inst->height < 1) {
+    return WEBRTC_VIDEO_CODEC_ERR_PARAMETER;
+  }
+  if (number_of_cores < 1) {
+    return WEBRTC_VIDEO_CODEC_ERR_PARAMETER;
+  }
+
+  int ret_val= Release();
+  if (ret_val < 0) {
+    return ret_val;
+  }
+
+  timestamp_ = 0;
+
+  if (&codec_ != inst) {
+    codec_ = *inst;
+  }
+
+  if (encoded_image_._buffer != NULL) {
+    delete [] encoded_image_._buffer;
+  }
+  encoded_image_._size = CalcBufferSize(kI420, codec_.width, codec_.height);
+  encoded_image_._buffer = new uint8_t[encoded_image_._size];
+  encoded_image_._completeFrame = true;
+
+
+  vCoder = avcodec_find_encoder(AV_CODEC_ID_H264);
+  if (!vCoder) {
+	  WEBRTC_TRACE(webrtc::kTraceApiCall, webrtc::kTraceVideoCoding, -1,
+		  	  "can't get H264 encoder");
+    return WEBRTC_VIDEO_CODEC_ERR_PARAMETER;
+  }
+
+  vCoderContext = avcodec_alloc_context3(vCoder);
+  if (!vCoderContext) {
+	  WEBRTC_TRACE(webrtc::kTraceApiCall, webrtc::kTraceVideoCoding, -1,
+			  "Error allocating vCoderContext");
+    return WEBRTC_VIDEO_CODEC_ERR_PARAMETER;
+  }
+
+  vCoderContext->bit_rate = inst->targetBitrate;
+  vCoderContext->rc_min_rate = inst->minBitrate;
+  vCoderContext->rc_max_rate = inst->maxBitrate; // VPX_CBR
+  vCoderContext->qmin = 0;
+  vCoderContext->qmax = 40; // rc_quantifiers
+  vCoderContext->profile = 3;
+  //    vCoderContext->frame_skip_threshold = 30;
+  vCoderContext->rc_buffer_aggressivity = 0.95;
+  //vCoderContext->rc_buffer_size = vCoderContext->bit_rate;
+  //vCoderContext->rc_initial_buffer_occupancy = vCoderContext->bit_rate / 2;
+  vCoderContext->rc_initial_buffer_occupancy = 500;
+
+  vCoderContext->rc_buffer_size = 1000;
+
+  vCoderContext->width = inst->width;
+  vCoderContext->height = inst->width;
+  vCoderContext->pix_fmt = PIX_FMT_YUV420P;
+  vCoderContext->time_base = (AVRational) {1, 90000};
+  //
+  vCoderContext->sample_aspect_ratio =
+    (AVRational) {inst->width,inst->width};
+  vCoderContext->thread_count = 1;
+
+  if (avcodec_open2(vCoderContext, vCoder, NULL) < 0) {
+	  WEBRTC_TRACE(webrtc::kTraceApiCall, webrtc::kTraceVideoCoding, -1,
+			  "Error opening video decoder");
+    return WEBRTC_VIDEO_CODEC_ERR_PARAMETER;
+  }
+
+  cPicture = avcodec_alloc_frame();
+  if (!cPicture) {
+	  WEBRTC_TRACE(webrtc::kTraceApiCall, webrtc::kTraceVideoCoding, -1,
+			  "Error allocating video frame");
+    return WEBRTC_VIDEO_CODEC_ERR_PARAMETER;
+  }
+
+  inited_ = true;
+  WEBRTC_TRACE(webrtc::kTraceApiCall, webrtc::kTraceVideoCoding, -1,
+               "H264EncoderImpl::InitEncode(width:%d, height:%d, framerate:%d, start_bitrate:%d, max_bitrate:%d)",
+               inst->width, inst->height, inst->maxFramerate, inst->startBitrate, inst->maxBitrate);
+
+  return WEBRTC_VIDEO_CODEC_OK;
+}
+
+int H264EncoderImpl::Encode(const I420VideoFrame& input_image,
+                           const CodecSpecificInfo* codec_specific_info,
+                           const std::vector<VideoFrameType>* frame_types) {
+  if (!inited_) {
+    return WEBRTC_VIDEO_CODEC_UNINITIALIZED;
+  }
+  if (input_image.IsZeroSize()) {
+    return WEBRTC_VIDEO_CODEC_ERR_PARAMETER;
+  }
+  if (encoded_complete_callback_ == NULL) {
+    return WEBRTC_VIDEO_CODEC_UNINITIALIZED;
+  }
+
+  VideoFrameType frame_type = kDeltaFrame;
+  // We only support one stream at the moment.
+  if (frame_types && frame_types->size() > 0) {
+    frame_type = (*frame_types)[0];
+  }
+
+  bool send_keyframe = (frame_type == kKeyFrame);
+//  bool send_keyframe = true;
+  if (send_keyframe) {
+	// TODO: force keyframe
+    WEBRTC_TRACE(webrtc::kTraceApiCall, webrtc::kTraceVideoCoding, -1,
+                 "H264EncoderImpl::EncodeKeyFrame(width:%d, height:%d)",
+                 input_image.width(), input_image.height());
+  }
+  // Check for change in frame size.
+  if (input_image.width() != codec_.width ||
+      input_image.height() != codec_.height) {
+    int ret = UpdateCodecFrameSize(input_image);
+    if (ret < 0) {
+      return ret;
+    }
+  }
+
+  int size = vCoderContext->width * vCoderContext->height;
+
+  cPicture->pts = AV_NOPTS_VALUE;
+  cPicture->data[0] = const_cast<uint8_t*>(input_image.buffer(kYPlane));;
+  cPicture->data[1] = const_cast<uint8_t*>(input_image.buffer(kUPlane));
+  cPicture->data[2] = const_cast<uint8_t*>(input_image.buffer(kVPlane));
+  cPicture->linesize[0] = input_image.stride(kYPlane);
+  cPicture->linesize[1] = input_image.stride(kUPlane);
+  cPicture->linesize[2] = input_image.stride(kVPlane);
+
+  AVPacket pkt;
+  av_init_packet(&pkt);
+  pkt.data = encoded_image_._buffer;
+  pkt.size = encoded_image_._length;
+
+  int got_packet = 0;
+  int ret = avcodec_encode_video2(vCoderContext, &pkt, cPicture, &got_packet);
+  if (!ret && got_packet && vCoderContext->coded_frame) {
+    vCoderContext->coded_frame->pts = pkt.pts;
+    vCoderContext->coded_frame->key_frame =
+      !!(pkt.flags & AV_PKT_FLAG_KEY);
+    encoded_image_._timeStamp       = input_image.timestamp();
+    encoded_image_.capture_time_ms_ = input_image.render_time_ms();
+
+    WEBRTC_TRACE(webrtc::kTraceApiCall, webrtc::kTraceVideoCoding, -1,
+                 "H264EncoderImpl::Encode() length:%d",
+                 encoded_image_._length);
+
+    // call back
+    encoded_complete_callback_->Encoded(encoded_image_, NULL, NULL);
+
+    if (!first_frame_encoded_) {
+      first_frame_encoded_ = true;
+    }
+  } else {
+	    WEBRTC_TRACE(webrtc::kTraceApiCall, webrtc::kTraceVideoCoding, -1,
+	                 "H264EncoderImpl::Encode() error, code is %d", ret);
+
+  }
+
+
+  return WEBRTC_VIDEO_CODEC_OK;
+}
+
+int H264EncoderImpl::RegisterEncodeCompleteCallback(
+    EncodedImageCallback* callback) {
+  encoded_complete_callback_ = callback;
+  return WEBRTC_VIDEO_CODEC_OK;
+}
+
+int H264EncoderImpl::SetChannelParameters(uint32_t /*packet_loss*/, int rtt) {
+  // ffs
+  return WEBRTC_VIDEO_CODEC_OK;
+}
+
+int H264EncoderImpl::UpdateCodecFrameSize(const I420VideoFrame& input_image) {
+  codec_.width = input_image.width();
+  codec_.height = input_image.height();
+  // ffs
+  return WEBRTC_VIDEO_CODEC_OK;
+}
+
+H264Decoder* H264Decoder::Create() {
+  return new H264DecoderImpl();
+}
+
+H264DecoderImpl::H264DecoderImpl()
+    : decode_complete_callback_(NULL),
+      inited_(false),
+      //feedback_mode_(false),
+      last_keyframe_(),
+      key_frame_required_(true),
+      buffer_with_start_code_(NULL) {
+
+  memset(&codec_, 0, sizeof(codec_));
+  buffer_with_start_code_ = new unsigned char [MAX_ENCODED_IMAGE_SIZE];
+  avcodec_register_all();
+  vDecoder = NULL;
+  vDecoderContext = NULL;
+  dPicture = NULL;
+  initWithContext_=false;
+
+}
+
+H264DecoderImpl::~H264DecoderImpl() {
+  inited_ = true;  // in order to do the actual release
+  Release();
+  delete [] buffer_with_start_code_;
+}
+
+int H264DecoderImpl::Reset() {
+  if (!inited_) {
+    return WEBRTC_VIDEO_CODEC_UNINITIALIZED;
+  }
+  InitDecode(&codec_, 1);
+  return WEBRTC_VIDEO_CODEC_OK;
+}
+
+int H264DecoderImpl::InitDecode(const VideoCodec* inst, int number_of_cores) {
+  if (inst == NULL) {
+    return WEBRTC_VIDEO_CODEC_ERR_PARAMETER;
+  }
+  int ret_val = Release();
+  if (ret_val < 0) {
+    return ret_val;
+  }
+  WEBRTC_TRACE(webrtc::kTraceApiCall, webrtc::kTraceVideoCoding, -1,
+               "H264DecoderImpl::InitDecode");
+
+  vDecoder = avcodec_find_decoder(AV_CODEC_ID_H264);
+  if (!vDecoder) {
+	  WEBRTC_TRACE(webrtc::kTraceApiCall, webrtc::kTraceVideoCoding, -1,
+			  "Error getting video decoder");
+    return WEBRTC_VIDEO_CODEC_ERR_PARAMETER;
+  }
+
+  vDecoderContext = avcodec_alloc_context3(vDecoder);
+  if (!vDecoderContext) {
+	  WEBRTC_TRACE(webrtc::kTraceApiCall, webrtc::kTraceVideoCoding, -1,
+			  "Error getting allocating decoder context");
+    return WEBRTC_VIDEO_CODEC_ERR_PARAMETER;
+  }
+
+  vDecoderContext->width = inst->width;
+  vDecoderContext->height = inst->height;
+
+  if (avcodec_open2(vDecoderContext, vDecoder, NULL) < 0) {
+	  WEBRTC_TRACE(webrtc::kTraceApiCall, webrtc::kTraceVideoCoding, -1,
+			  "Error opening video decoder");
+    return WEBRTC_VIDEO_CODEC_ERR_PARAMETER;
+  }
+
+  dPicture = avcodec_alloc_frame();
+  if (!dPicture) {
+	  WEBRTC_TRACE(webrtc::kTraceApiCall, webrtc::kTraceVideoCoding, -1,
+			  "Error allocating video frame");
+    return WEBRTC_VIDEO_CODEC_ERR_PARAMETER;
+  }
+
+  if (&codec_ != inst) {
+    // Save VideoCodec instance for later; mainly for duplicating the decoder.
+    codec_ = *inst;
+  }
+
+  inited_ = true;
+
+  // Always start with a complete key frame.
+  key_frame_required_ = true;
+  WEBRTC_TRACE(webrtc::kTraceApiCall, webrtc::kTraceVideoCoding, -1,
+               "H264DecoderImpl::InitDecode(width:%d, height:%d, framerate:%d, start_bitrate:%d, max_bitrate:%d)",
+               inst->width, inst->height, inst->maxFramerate, inst->startBitrate, inst->maxBitrate);
+  return WEBRTC_VIDEO_CODEC_OK;
+}
+
+int H264DecoderImpl::Decode(const EncodedImage& input_image,
+                           bool missing_frames,
+                           const RTPFragmentationHeader* fragmentation,
+                           const CodecSpecificInfo* codec_specific_info,
+                           int64_t /*render_time_ms*/) {
+  if (!inited_) {
+    WEBRTC_TRACE(webrtc::kTraceError, webrtc::kTraceVideoCoding, -1,
+                 "H264DecoderImpl::Decode, decoder is not initialized");
+    return WEBRTC_VIDEO_CODEC_UNINITIALIZED;
+  }
+
+  if (decode_complete_callback_ == NULL) {
+    WEBRTC_TRACE(webrtc::kTraceError, webrtc::kTraceVideoCoding, -1,
+                 "H264DecoderImpl::Decode, decode complete call back is not set");
+    return WEBRTC_VIDEO_CODEC_UNINITIALIZED;
+  }
+
+  if (input_image._buffer == NULL) {
+    WEBRTC_TRACE(webrtc::kTraceError, webrtc::kTraceVideoCoding, -1,
+                "H264DecoderImpl::Decode, null buffer");
+    return WEBRTC_VIDEO_CODEC_ERR_PARAMETER;
+  }
+  if (!codec_specific_info) {
+    WEBRTC_TRACE(webrtc::kTraceError, webrtc::kTraceVideoCoding, -1,
+                 "H264EncoderImpl::Decode, no codec info");
+    return WEBRTC_VIDEO_CODEC_ERROR;
+  }
+  if (codec_specific_info->codecType != kVideoCodecH264) {
+    WEBRTC_TRACE(webrtc::kTraceError, webrtc::kTraceVideoCoding, -1,
+                 "H264EncoderImpl::Decode, non h264 codec %d", codec_specific_info->codecType);
+    return WEBRTC_VIDEO_CODEC_ERROR;
+  }
+
+  unsigned char nalu_header = codec_specific_info->codecSpecific.H264.nalu_header;
+  unsigned char nal_type = nalu_header & 0x1F;
+  bool single_nalu = codec_specific_info->codecSpecific.H264.single_nalu;
+
+  WEBRTC_TRACE(webrtc::kTraceApiCall, webrtc::kTraceVideoCoding, -1,
+	           "H264DecoderImpl::Decode(frame_type:%d, length:%d, nal_type:%d, timestamp:%u",
+	            input_image._frameType, input_image._length, nal_type, input_image._timeStamp);
+
+#if 0
+  // Always start with a complete key frame.
+  if (key_frame_required_) {
+    if (input_image._frameType != kKeyFrame)
+      return WEBRTC_VIDEO_CODEC_ERROR;
+    // We have a key frame - is it complete?
+    if (input_image._completeFrame) {
+      key_frame_required_ = false;
+    } else {
+      return WEBRTC_VIDEO_CODEC_ERROR;
+    }
+  }
+#endif
+  if (vDecoder == 0 || vDecoderContext == 0){
+    return WEBRTC_VIDEO_CODEC_UNINITIALIZED;
+  }
+
+  AVPacket avpkt;
+  av_init_packet(&avpkt);
+
+  avpkt.data = input_image._buffer;
+  avpkt.size = input_image._length;
+
+  int got_picture;
+  int len;
+
+  while (avpkt.size > 0) {
+
+    len = avcodec_decode_video2(vDecoderContext, dPicture, &got_picture,
+        &avpkt);
+
+    if (len < 0) {
+        WEBRTC_TRACE(webrtc::kTraceError, webrtc::kTraceVideoCoding, -1,
+        		"Error decoding video frame");
+      return WEBRTC_VIDEO_CODEC_ERROR;
+    }
+    if (got_picture) {
+    	  int outSize = vDecoderContext->height * vDecoderContext->width;
+
+    	  decoded_image_.CreateFrame(dPicture->linesize[0], dPicture->data[0],
+    			  	  	  	  	  	 dPicture->linesize[1], dPicture->data[1],
+    			  	  	  	  	  	 dPicture->linesize[2], dPicture->data[2],
+    	                             vDecoderContext->width,
+    	                             vDecoderContext->height,
+    	                             vDecoderContext->width,
+    	                             vDecoderContext->width / 2,
+    	                             vDecoderContext->width / 2);
+    	  decoded_image_.set_timestamp(input_image._timeStamp);
+    	  decode_complete_callback_->Decoded(decoded_image_);
+
+    	  av_free_packet(&avpkt);
+    	  return WEBRTC_VIDEO_CODEC_OK;
+    }
+    avpkt.size -= len;
+    avpkt.data += len;
+  }
+
+  if (!got_picture) {
+      WEBRTC_TRACE(webrtc::kTraceError, webrtc::kTraceVideoCoding, -1,
+      		"did not get picture from decoder");
+    return WEBRTC_VIDEO_CODEC_ERROR;
+  }
+
+  return WEBRTC_VIDEO_CODEC_OK;
+}
+
+int H264DecoderImpl::RegisterDecodeCompleteCallback(
+    DecodedImageCallback* callback) {
+  decode_complete_callback_ = callback;
+  return WEBRTC_VIDEO_CODEC_OK;
+}
+
+int H264DecoderImpl::Release() {
+  if (last_keyframe_._buffer != NULL) {
+    delete [] last_keyframe_._buffer;
+    last_keyframe_._buffer = NULL;
+  }
+  if (!initWithContext_ && vDecoderContext != NULL)
+    avcodec_close(vDecoderContext);
+  if (dPicture != NULL)
+    avcodec_free_frame(&dPicture);
+
+  inited_ = false;
+  return WEBRTC_VIDEO_CODEC_OK;
+}
+
+VideoDecoder* H264DecoderImpl::Copy() {
+  // Sanity checks.
+  if (!inited_) {
+    // Not initialized.
+    assert(false);
+    return NULL;
+  }
+  if (decoded_image_.IsZeroSize()) {
+    // Nothing has been decoded before; cannot clone.
+    return NULL;
+  }
+  if (last_keyframe_._buffer == NULL) {
+    // Cannot clone if we have no key frame to start with.
+    return NULL;
+  }
+  // Create a new VideoDecoder object
+  H264DecoderImpl *copy = new H264DecoderImpl;
+
+  // Initialize the new decoder
+  if (copy->InitDecode(&codec_, 1) != WEBRTC_VIDEO_CODEC_OK) {
+    delete copy;
+    return NULL;
+  }
+
+  return static_cast<VideoDecoder*>(copy);
+}
+
+}  // namespace webrtc
diff --git a/src/webrtc/modules/video_coding/codecs/h264/ffmpeg_h264_impl.h b/src/webrtc/modules/video_coding/codecs/h264/ffmpeg_h264_impl.h
new file mode 100644
index 0000000..fd5c597
--- /dev/null
+++ b/src/webrtc/modules/video_coding/codecs/h264/ffmpeg_h264_impl.h
@@ -0,0 +1,211 @@
+/*
+ *  Copyright (c) 2012 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ *
+ * WEBRTC H264 wrapper interface
+ */
+
+#ifndef WEBRTC_MODULES_VIDEO_CODING_CODECS_H264_IMPL_H_
+#define WEBRTC_MODULES_VIDEO_CODING_CODECS_H264_IMPL_H_
+
+extern "C" {
+#ifndef INT64_C
+#define INT64_C(c) (c ## LL)
+#define UINT64_C(c) (c ## ULL)
+#endif
+#include <libavutil/avutil.h>
+#include <libavcodec/avcodec.h>
+}
+
+#include "webrtc/modules/video_coding/codecs/h264/include/h264.h"
+
+namespace webrtc {
+
+class H264EncoderImpl : public H264Encoder {
+ public:
+  H264EncoderImpl();
+
+  virtual ~H264EncoderImpl();
+
+  // Free encoder memory.
+  //
+  // Return value                : WEBRTC_VIDEO_CODEC_OK if OK, < 0 otherwise.
+  virtual int Release();
+
+  // Initialize the encoder with the information from the codecSettings
+  //
+  // Input:
+  //          - codec_settings    : Codec settings
+  //          - number_of_cores   : Number of cores available for the encoder
+  //          - max_payload_size  : The maximum size each payload is allowed
+  //                                to have. Usually MTU - overhead.
+  //
+  // Return value                 : Set bit rate if OK
+  //                                <0 - Errors:
+  //                                  WEBRTC_VIDEO_CODEC_ERR_PARAMETER
+  //                                  WEBRTC_VIDEO_CODEC_ERR_SIZE
+  //                                  WEBRTC_VIDEO_CODEC_LEVEL_EXCEEDED
+  //                                  WEBRTC_VIDEO_CODEC_MEMORY
+  //                                  WEBRTC_VIDEO_CODEC_ERROR
+  virtual int InitEncode(const VideoCodec* codec_settings,
+                         int number_of_cores,
+                         uint32_t max_payload_size);
+
+  // Encode an I420 image (as a part of a video stream). The encoded image
+  // will be returned to the user through the encode complete callback.
+  //
+  // Input:
+  //          - input_image       : Image to be encoded
+  //          - frame_types       : Frame type to be generated by the encoder.
+  //
+  // Return value                 : WEBRTC_VIDEO_CODEC_OK if OK
+  //                                <0 - Errors:
+  //                                  WEBRTC_VIDEO_CODEC_ERR_PARAMETER
+  //                                  WEBRTC_VIDEO_CODEC_MEMORY
+  //                                  WEBRTC_VIDEO_CODEC_ERROR
+  //                                  WEBRTC_VIDEO_CODEC_TIMEOUT
+
+  virtual int Encode(const I420VideoFrame& input_image,
+                     const CodecSpecificInfo* codec_specific_info,
+                     const std::vector<VideoFrameType>* frame_types);
+
+  // Register an encode complete callback object.
+  //
+  // Input:
+  //          - callback         : Callback object which handles encoded images.
+  //
+  // Return value                : WEBRTC_VIDEO_CODEC_OK if OK, < 0 otherwise.
+  virtual int RegisterEncodeCompleteCallback(EncodedImageCallback* callback);
+
+  // Inform the encoder of the new packet loss rate and the round-trip time of
+  // the network.
+  //
+  //          - packet_loss : Fraction lost
+  //                          (loss rate in percent = 100 * packetLoss / 255)
+  //          - rtt         : Round-trip time in milliseconds
+  // Return value           : WEBRTC_VIDEO_CODEC_OK if OK
+  //                          <0 - Errors: WEBRTC_VIDEO_CODEC_ERROR
+  //
+  virtual int SetChannelParameters(uint32_t packet_loss, int rtt);
+
+  // Inform the encoder about the new target bit rate.
+  //
+  //          - new_bitrate_kbit : New target bit rate
+  //          - frame_rate       : The target frame rate
+  //
+  // Return value                : WEBRTC_VIDEO_CODEC_OK if OK, < 0 otherwise.
+  virtual int SetRates(uint32_t new_bitrate_kbit, uint32_t frame_rate);
+
+ private:
+  // Update frame size for codec.
+  int UpdateCodecFrameSize(const I420VideoFrame& input_image);
+
+  //void PopulateCodecSpecific(CodecSpecificInfo* codec_specific,
+  //                           const vpx_codec_cx_pkt& pkt,
+  //                           uint32_t timestamp);
+
+  EncodedImage encoded_image_;
+  EncodedImageCallback* encoded_complete_callback_;
+  VideoCodec codec_;
+  bool inited_;
+  bool first_frame_encoded_;
+  int64_t timestamp_;
+
+  AVCodec* vCoder;
+  AVCodecContext* vCoderContext;
+  AVFrame* cPicture;
+};  // end of H264Encoder class
+
+
+class H264DecoderImpl : public H264Decoder {
+ public:
+  enum {
+    //MAX_ENCODED_IMAGE_SIZE = 10240
+	 MAX_ENCODED_IMAGE_SIZE = 102400
+  };
+
+  H264DecoderImpl();
+
+  virtual ~H264DecoderImpl();
+
+  // Initialize the decoder.
+  //
+  // Return value         :  WEBRTC_VIDEO_CODEC_OK.
+  //                        <0 - Errors:
+  //                                  WEBRTC_VIDEO_CODEC_ERROR
+  virtual int InitDecode(const VideoCodec* inst, int number_of_cores);
+
+  // Decode encoded image (as a part of a video stream). The decoded image
+  // will be returned to the user through the decode complete callback.
+  //
+  // Input:
+  //          - input_image         : Encoded image to be decoded
+  //          - missing_frames      : True if one or more frames have been lost
+  //                                  since the previous decode call.
+  //          - fragmentation       : Specifies the start and length of each H264
+  //                                  partition.
+  //          - codec_specific_info : pointer to specific codec data
+  //          - render_time_ms      : Render time in Ms
+  //
+  // Return value                 : WEBRTC_VIDEO_CODEC_OK if OK
+  //                                <0 - Errors:
+  //                                      WEBRTC_VIDEO_CODEC_ERROR
+  //                                      WEBRTC_VIDEO_CODEC_ERR_PARAMETER
+  virtual int Decode(const EncodedImage& input_image,
+                     bool missing_frames,
+                     const RTPFragmentationHeader* fragmentation,
+                     const CodecSpecificInfo* codec_specific_info,
+                     int64_t /*render_time_ms*/);
+
+  // Register a decode complete callback object.
+  //
+  // Input:
+  //          - callback         : Callback object which handles decoded images.
+  //
+  // Return value                : WEBRTC_VIDEO_CODEC_OK if OK, < 0 otherwise.
+  virtual int RegisterDecodeCompleteCallback(DecodedImageCallback* callback);
+
+  // Free decoder memory.
+  //
+  // Return value                : WEBRTC_VIDEO_CODEC_OK if OK
+  //                               <0 - Errors:
+  //                                      WEBRTC_VIDEO_CODEC_ERROR
+  virtual int Release();
+
+  // Reset decoder state and prepare for a new call.
+  //
+  // Return value         : WEBRTC_VIDEO_CODEC_OK.
+  //                        <0 - Errors:
+  //                                  WEBRTC_VIDEO_CODEC_UNINITIALIZED
+  //                                  WEBRTC_VIDEO_CODEC_ERROR
+  virtual int Reset();
+
+  // Create a copy of the codec and its internal state.
+  //
+  // Return value                : A copy of the instance if OK, NULL otherwise.
+  virtual VideoDecoder* Copy();
+
+ private:
+  I420VideoFrame decoded_image_;
+  DecodedImageCallback* decode_complete_callback_;
+  bool inited_;
+
+  VideoCodec codec_;
+  EncodedImage last_keyframe_;
+  bool key_frame_required_;
+  unsigned char* buffer_with_start_code_;
+
+  AVCodec* vDecoder;
+  bool initWithContext_;
+  AVCodecContext* vDecoderContext;
+  AVFrame* dPicture;
+
+};  // end of H264Decoder class
+}  // namespace webrtc
+
+#endif  // WEBRTC_MODULES_VIDEO_CODING_CODECS_H264_IMPL_H_
diff --git a/src/webrtc/modules/video_coding/codecs/h264/h264.gyp b/src/webrtc/modules/video_coding/codecs/h264/h264.gyp
new file mode 100644
index 0000000..cd5e055
--- /dev/null
+++ b/src/webrtc/modules/video_coding/codecs/h264/h264.gyp
@@ -0,0 +1,53 @@
+# Copyright (c) 2012 The WebRTC project authors. All Rights Reserved.
+#
+# Use of this source code is governed by a BSD-style license
+# that can be found in the LICENSE file in the root of the source
+# tree. An additional intellectual property rights grant can be found
+# in the file PATENTS.  All contributing project authors may
+# be found in the AUTHORS file in the root of the source tree.
+
+{
+   'variables' : {	
+      'openh264_dir%': '<(DEPTH)/../../openh264',
+      'libav_dir%': '<(DEPTH)/../../../build/libdeps/libav-9.13',
+   },         
+  'includes': [
+    '../../../../build/common.gypi',
+  ],
+  'targets': [
+    {
+      'target_name': 'webrtc_h264',
+      'type': 'static_library',
+      'dependencies': [
+        '<(webrtc_root)/common_video/common_video.gyp:common_video',
+        '<(webrtc_root)/modules/video_coding/utility/video_coding_utility.gyp:video_coding_utility',
+        '<(webrtc_root)/system_wrappers/source/system_wrappers.gyp:system_wrappers',
+      ],
+      'include_dirs': [
+        '<(openh264_dir)/codec/api/svc',
+		'<(libav_dir)',               
+        'include',
+        '<(webrtc_root)/common_video/interface',
+        '<(webrtc_root)/modules/video_coding/codecs/interface',
+        '<(webrtc_root)/modules/interface',
+      ],
+      'direct_dependent_settings': {
+        'include_dirs': [
+          'include',
+          '<(webrtc_root)/common_video/interface',
+          '<(webrtc_root)/modules/video_coding/codecs/interface',
+        ],
+      },
+      'link_settings': {
+        'libraries': [
+          '-L<(openh264_dir)',
+          '-lopenh264',
+        ],
+      },
+      'sources': [
+        'h264_impl.h',
+        'h264_impl.cc',
+      ],
+    },
+  ], # targets
+}
diff --git a/src/webrtc/modules/video_coding/codecs/h264/h264_impl.cc b/src/webrtc/modules/video_coding/codecs/h264/h264_impl.cc
new file mode 100644
index 0000000..789ad19
--- /dev/null
+++ b/src/webrtc/modules/video_coding/codecs/h264/h264_impl.cc
@@ -0,0 +1,521 @@
+/*
+ *  Copyright (c) 2012 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ *
+ * This file contains the WEBRTC H264 wrapper implementation
+ *
+ */
+
+#include "webrtc/modules/video_coding/codecs/h264/h264_impl.h"
+
+#include <stdlib.h>
+#include <string.h>
+#include <time.h>
+#include <vector>
+#include <climits>
+
+#include "webrtc/common.h"
+#include "webrtc/common_video/libyuv/include/webrtc_libyuv.h"
+#include "webrtc/modules/interface/module_common_types.h"
+#include "webrtc/system_wrappers/interface/trace.h"
+#include "webrtc/system_wrappers/interface/tick_util.h"
+#include "webrtc/system_wrappers/interface/trace_event.h"
+
+namespace webrtc {
+
+H264Encoder* H264Encoder::Create() {
+  return new H264EncoderImpl();
+}
+
+H264EncoderImpl::H264EncoderImpl()
+    : encoded_image_(),
+      encoded_complete_callback_(NULL),
+      inited_(false),
+      first_frame_encoded_(false),
+      timestamp_(0),
+      encoder_(NULL) {
+  memset(&codec_, 0, sizeof(codec_));
+  uint32_t seed = static_cast<uint32_t>(TickTime::MillisecondTimestamp());
+  srand(seed);
+}
+
+H264EncoderImpl::~H264EncoderImpl() {
+  Release();
+}
+
+int H264EncoderImpl::Release() {
+  if (encoded_image_._buffer != NULL) {
+    delete [] encoded_image_._buffer;
+    encoded_image_._buffer = NULL;
+  }
+  if (encoder_ != NULL) {
+    WelsDestroySVCEncoder(encoder_);
+    encoder_ = NULL;
+  }
+  inited_ = false;
+  return WEBRTC_VIDEO_CODEC_OK;
+}
+
+int H264EncoderImpl::SetRates(uint32_t new_bitrate_kbit,
+                             uint32_t new_framerate) {
+  WEBRTC_TRACE(webrtc::kTraceApiCall, webrtc::kTraceVideoCoding, -1,
+               "H264EncoderImpl::SetRates(%d, %d)", new_bitrate_kbit, new_framerate);
+  if (!inited_) {
+    return WEBRTC_VIDEO_CODEC_UNINITIALIZED;
+  }
+  if (new_framerate < 1) {
+    return WEBRTC_VIDEO_CODEC_ERR_PARAMETER;
+  }
+  // update bit rate
+  if (codec_.maxBitrate > 0 && new_bitrate_kbit > codec_.maxBitrate) {
+    new_bitrate_kbit = codec_.maxBitrate;
+  }
+
+  return WEBRTC_VIDEO_CODEC_OK;
+}
+
+int H264EncoderImpl::InitEncode(const VideoCodec* inst,
+                               int number_of_cores,
+                               uint32_t /*max_payload_size*/) {
+  if (inst == NULL) {
+    return WEBRTC_VIDEO_CODEC_ERR_PARAMETER;
+  }
+  if (inst->maxFramerate < 1) {
+    return WEBRTC_VIDEO_CODEC_ERR_PARAMETER;
+  }
+  // allow zero to represent an unspecified maxBitRate
+  if (inst->maxBitrate > 0 && inst->startBitrate > inst->maxBitrate) {
+    return WEBRTC_VIDEO_CODEC_ERR_PARAMETER;
+  }
+  if (inst->width < 1 || inst->height < 1) {
+    return WEBRTC_VIDEO_CODEC_ERR_PARAMETER;
+  }
+  if (number_of_cores < 1) {
+    return WEBRTC_VIDEO_CODEC_ERR_PARAMETER;
+  }
+
+  int ret_val= Release();
+  if (ret_val < 0) {
+    return ret_val;
+  }
+  if (encoder_ == NULL) {
+	ret_val = WelsCreateSVCEncoder(&encoder_);
+    if (ret_val != 0) {
+     WEBRTC_TRACE(webrtc::kTraceError, webrtc::kTraceVideoCoding, -1,
+  	              "H264EncoderImpl::InitEncode() fails to create encoder ret_val %d",
+    	           ret_val);
+      return WEBRTC_VIDEO_CODEC_ERROR;
+    }
+  }
+  SEncParamBase param;
+  memset (&param, 0, sizeof(SEncParamBase));
+
+  param.fMaxFrameRate = inst->maxFramerate;
+  param.iPicWidth = inst->width;
+  param.iPicHeight = inst->height;
+  param.iTargetBitrate = inst->maxBitrate * 1000;
+
+  WEBRTC_TRACE(webrtc::kTraceError, webrtc::kTraceVideoCoding, -1,
+               "H264EncoderImpl::InitEncode(): maxFrameRate %f, width %d, height %d, targetbitRate %d",
+               param.fMaxFrameRate, param.iPicWidth,  param.iPicHeight, param.iTargetBitrate);
+
+  ret_val =  encoder_->Initialize(&param);
+  if (ret_val != 0) {
+    WEBRTC_TRACE(webrtc::kTraceError, webrtc::kTraceVideoCoding, -1,
+                 "H264EncoderImpl::InitEncode() fails to initialize encoder ret_val %d",
+                 ret_val);
+    WelsDestroySVCEncoder(encoder_);
+    encoder_ = NULL;
+    return WEBRTC_VIDEO_CODEC_ERROR;
+  }
+  timestamp_ = 0;
+
+  if (&codec_ != inst) {
+    codec_ = *inst;
+  }
+
+  if (encoded_image_._buffer != NULL) {
+    delete [] encoded_image_._buffer;
+  }
+  encoded_image_._size = CalcBufferSize(kI420, codec_.width, codec_.height);
+  encoded_image_._buffer = new uint8_t[encoded_image_._size];
+  encoded_image_._completeFrame = true;
+
+//  int32_t iTraceLevel = WELS_LOG_DETAIL;
+//  encoder_->SetOption (ENCODER_OPTION_TRACE_LEVEL, &iTraceLevel);
+//  decoder_->SetOption (DECODER_OPTION_TRACE_LEVEL, &iTraceLevel);
+
+  inited_ = true;
+  WEBRTC_TRACE(webrtc::kTraceApiCall, webrtc::kTraceVideoCoding, -1,
+               "H264EncoderImpl::InitEncode(width:%d, height:%d, framerate:%d, start_bitrate:%d, max_bitrate:%d)",
+               inst->width, inst->height, inst->maxFramerate, inst->startBitrate, inst->maxBitrate);
+
+  int32_t iIdrInterval = 320;
+  int32_t encIdrInt;
+  encoder_->GetOption(ENCODER_OPTION_IDR_INTERVAL, &encIdrInt);
+  encoder_->SetOption(ENCODER_OPTION_IDR_INTERVAL, &iIdrInterval);
+  encoder_->GetOption(ENCODER_OPTION_IDR_INTERVAL, &encIdrInt);
+ WEBRTC_TRACE(webrtc::kTraceApiCall, webrtc::kTraceVideoCoding, -1,
+				"H264EncoderImpl::SetOption(IdrInterval:%d)", encIdrInt);
+
+  return WEBRTC_VIDEO_CODEC_OK;
+}
+
+
+int H264EncoderImpl::Encode(const I420VideoFrame& input_image,
+                           const CodecSpecificInfo* codec_specific_info,
+                           const std::vector<VideoFrameType>* frame_types) {
+  if (!inited_) {
+    return WEBRTC_VIDEO_CODEC_UNINITIALIZED;
+  }
+  if (input_image.IsZeroSize()) {
+    return WEBRTC_VIDEO_CODEC_ERR_PARAMETER;
+  }
+  if (encoded_complete_callback_ == NULL) {
+    return WEBRTC_VIDEO_CODEC_UNINITIALIZED;
+  }
+
+  VideoFrameType frame_type = kDeltaFrame;
+  // We only support one stream at the moment.
+  if (frame_types && frame_types->size() > 0) {
+    frame_type = (*frame_types)[0];
+  }
+
+  bool send_keyframe = (frame_type == kKeyFrame);
+//  bool send_keyframe = true;
+  if (send_keyframe) {
+    encoder_->ForceIntraFrame(true);
+    WEBRTC_TRACE(webrtc::kTraceApiCall, webrtc::kTraceVideoCoding, -1,
+                 "H264EncoderImpl::EncodeKeyFrame(width:%d, height:%d)",
+                 input_image.width(), input_image.height());
+  }
+  // Check for change in frame size.
+  if (input_image.width() != codec_.width ||
+      input_image.height() != codec_.height) {
+    int ret = UpdateCodecFrameSize(input_image);
+    if (ret < 0) {
+      return ret;
+    }
+  }
+
+  SFrameBSInfo info;
+  memset(&info, 0, sizeof(SFrameBSInfo));
+
+  SSourcePicture pic;
+  memset(&pic,0,sizeof(SSourcePicture));
+  pic.iPicWidth = input_image.width();
+  pic.iPicHeight = input_image.height();
+  pic.iColorFormat = videoFormatI420;
+
+  pic.iStride[0] = input_image.stride(kYPlane);
+  pic.iStride[1] = input_image.stride(kUPlane);
+  pic.iStride[2] = input_image.stride(kVPlane);
+
+  pic.pData[0]   = const_cast<uint8_t*>(input_image.buffer(kYPlane));
+  pic.pData[1]   = const_cast<uint8_t*>(input_image.buffer(kUPlane));
+  pic.pData[2]   = const_cast<uint8_t*>(input_image.buffer(kVPlane));
+
+  int retVal = encoder_->EncodeFrame(&pic, &info);
+  if (retVal == videoFrameTypeSkip) {
+    return WEBRTC_VIDEO_CODEC_OK;
+  }
+
+  int layer = 0;
+  //uint8_t* pbuff = encoded_image_._buffer;
+  while (layer < info.iLayerNum) {
+    const SLayerBSInfo* layer_bs_info = &info.sLayerInfo[layer];
+    if (layer_bs_info != NULL) {
+      int layer_size = 0;
+      //int nal_begin = 0;
+      int nal_begin  = 4;
+      uint8_t* nal_buffer = NULL;
+      char nal_type = 0;
+      for (int nal_index = 0; nal_index < layer_bs_info->iNalCount; nal_index++) {
+        nal_buffer  = layer_bs_info->pBsBuf + nal_begin;
+        nal_type    = (nal_buffer[0] & 0x1F);
+        //nal_type    = (nal_buffer[4] & 0x1F);
+        layer_size += layer_bs_info->pNalLengthInByte[nal_index];
+        nal_begin += layer_bs_info->pNalLengthInByte[nal_index];
+        if (nal_type == 14) {
+          continue;
+        }
+        encoded_image_._length          = layer_bs_info->pNalLengthInByte[nal_index] - 4;
+        //encoded_image_._length        = layer_bs_info->pNalLengthInByte[nal_index];
+        encoded_image_._frameType       = frame_type;
+        encoded_image_._timeStamp       = input_image.timestamp();
+        encoded_image_.capture_time_ms_ = input_image.render_time_ms();
+        memcpy(encoded_image_._buffer, nal_buffer, encoded_image_._length);
+        // encoded_image_._encodedHeight
+        // encoded_image_._encodedWidth
+
+        WEBRTC_TRACE(webrtc::kTraceApiCall, webrtc::kTraceVideoCoding, -1,
+                     "H264EncoderImpl::Encode() nal_type %d, length:%d",
+                     nal_type, encoded_image_._length);
+
+        // call back
+        encoded_complete_callback_->Encoded(encoded_image_, NULL, NULL);
+
+        if (!first_frame_encoded_) {
+          first_frame_encoded_ = true;
+        }
+      } // for
+    }
+    layer++;
+  }
+  return WEBRTC_VIDEO_CODEC_OK;
+}
+
+int H264EncoderImpl::RegisterEncodeCompleteCallback(
+    EncodedImageCallback* callback) {
+  encoded_complete_callback_ = callback;
+  return WEBRTC_VIDEO_CODEC_OK;
+}
+
+int H264EncoderImpl::SetChannelParameters(uint32_t /*packet_loss*/, int rtt) {
+  // ffs
+  return WEBRTC_VIDEO_CODEC_OK;
+}
+
+int H264EncoderImpl::UpdateCodecFrameSize(const I420VideoFrame& input_image) {
+  codec_.width = input_image.width();
+  codec_.height = input_image.height();
+  // ffs
+  return WEBRTC_VIDEO_CODEC_OK;
+}
+
+H264Decoder* H264Decoder::Create() {
+  return new H264DecoderImpl();
+}
+
+H264DecoderImpl::H264DecoderImpl()
+    : decode_complete_callback_(NULL),
+      inited_(false),
+      //feedback_mode_(false),
+      decoder_(NULL),
+      last_keyframe_(),
+      key_frame_required_(true),
+      buffer_with_start_code_(NULL) {
+  memset(&codec_, 0, sizeof(codec_));
+  buffer_with_start_code_ = new unsigned char [MAX_ENCODED_IMAGE_SIZE];
+}
+
+H264DecoderImpl::~H264DecoderImpl() {
+  inited_ = true;  // in order to do the actual release
+  Release();
+  delete [] buffer_with_start_code_;
+}
+
+int H264DecoderImpl::Reset() {
+  if (!inited_) {
+    return WEBRTC_VIDEO_CODEC_UNINITIALIZED;
+  }
+  InitDecode(&codec_, 1);
+  return WEBRTC_VIDEO_CODEC_OK;
+}
+
+int H264DecoderImpl::InitDecode(const VideoCodec* inst, int number_of_cores) {
+  if (inst == NULL) {
+    return WEBRTC_VIDEO_CODEC_ERR_PARAMETER;
+  }
+  int ret_val = Release();
+  if (ret_val < 0) {
+    return ret_val;
+  }
+  if (decoder_ == NULL) {
+    ret_val = WelsCreateDecoder(&decoder_);
+    if (ret_val != 0) {
+      decoder_ = NULL;
+      return WEBRTC_VIDEO_CODEC_ERROR;
+    }
+  }
+  SDecodingParam dec_param;
+  memset(&dec_param, 0, sizeof(SDecodingParam));
+  dec_param.eOutputColorFormat = videoFormatI420;
+  dec_param.uiTargetDqLayer = UCHAR_MAX;
+  dec_param.eEcActiveIdc = ERROR_CON_SLICE_COPY;
+  //dec_param.eEcActiveIdc = ERROR_CON_DISABLE;
+  dec_param.sVideoProperty.eVideoBsType = VIDEO_BITSTREAM_AVC;
+  ret_val = decoder_->Initialize(&dec_param);
+  if (ret_val != 0) {
+    decoder_->Uninitialize();
+    WelsDestroyDecoder(decoder_);
+    decoder_ = NULL;
+    return WEBRTC_VIDEO_CODEC_ERROR;
+  }
+
+  if (&codec_ != inst) {
+    // Save VideoCodec instance for later; mainly for duplicating the decoder.
+    codec_ = *inst;
+  }
+
+//  int32_t iTraceLevel = WELS_LOG_DETAIL;
+//  decoder_->SetOption (DECODER_OPTION_TRACE_LEVEL, &iTraceLevel);
+
+  inited_ = true;
+
+  // Always start with a complete key frame.
+  key_frame_required_ = true;
+  WEBRTC_TRACE(webrtc::kTraceApiCall, webrtc::kTraceVideoCoding, -1,
+               "H264DecoderImpl::InitDecode(width:%d, height:%d, framerate:%d, start_bitrate:%d, max_bitrate:%d)",
+               inst->width, inst->height, inst->maxFramerate, inst->startBitrate, inst->maxBitrate);
+  return WEBRTC_VIDEO_CODEC_OK;
+}
+
+int H264DecoderImpl::Decode(const EncodedImage& input_image,
+                           bool missing_frames,
+                           const RTPFragmentationHeader* fragmentation,
+                           const CodecSpecificInfo* codec_specific_info,
+                           int64_t /*render_time_ms*/) {
+  if (!inited_) {
+    WEBRTC_TRACE(webrtc::kTraceError, webrtc::kTraceVideoCoding, -1,
+                 "H264DecoderImpl::Decode, decoder is not initialized");
+    return WEBRTC_VIDEO_CODEC_UNINITIALIZED;
+  }
+
+  if (decode_complete_callback_ == NULL) {
+    WEBRTC_TRACE(webrtc::kTraceError, webrtc::kTraceVideoCoding, -1,
+                 "H264DecoderImpl::Decode, decode complete call back is not set");
+    return WEBRTC_VIDEO_CODEC_UNINITIALIZED;
+  }
+
+  if (input_image._buffer == NULL) {
+    WEBRTC_TRACE(webrtc::kTraceError, webrtc::kTraceVideoCoding, -1,
+                "H264DecoderImpl::Decode, null buffer");
+    return WEBRTC_VIDEO_CODEC_ERR_PARAMETER;
+  }
+  if (!codec_specific_info) {
+    WEBRTC_TRACE(webrtc::kTraceError, webrtc::kTraceVideoCoding, -1,
+                 "H264EncoderImpl::Decode, no codec info");
+    return WEBRTC_VIDEO_CODEC_ERROR;
+  }
+  if (codec_specific_info->codecType != kVideoCodecH264) {
+    WEBRTC_TRACE(webrtc::kTraceError, webrtc::kTraceVideoCoding, -1,
+                 "H264EncoderImpl::Decode, non h264 codec %d", codec_specific_info->codecType);
+    return WEBRTC_VIDEO_CODEC_ERROR;
+  }
+
+  unsigned char nalu_header = codec_specific_info->codecSpecific.H264.nalu_header;
+  unsigned char nal_type = nalu_header & 0x1F;
+  bool single_nalu = codec_specific_info->codecSpecific.H264.single_nalu;
+
+  WEBRTC_TRACE(webrtc::kTraceApiCall, webrtc::kTraceVideoCoding, -1,
+	           "H264DecoderImpl::Decode(frame_type:%d, length:%d, nal_type:%d, timestamp:%u",
+	            input_image._frameType, input_image._length, nal_type, input_image._timeStamp);
+
+#if 0
+  // Always start with a complete key frame.
+  if (key_frame_required_) {
+    if (input_image._frameType != kKeyFrame)
+      return WEBRTC_VIDEO_CODEC_ERROR;
+    // We have a key frame - is it complete?
+    if (input_image._completeFrame) {
+      key_frame_required_ = false;
+    } else {
+      return WEBRTC_VIDEO_CODEC_ERROR;
+    }
+  }
+#endif
+
+
+  void* data[3];
+  memset(data, 0, sizeof(data));
+  SBufferInfo buffer_info;
+  memset(&buffer_info, 0, sizeof(SBufferInfo));
+
+  unsigned char start_code[] = {0, 0, 0, 1};
+  memset(buffer_with_start_code_, 0, MAX_ENCODED_IMAGE_SIZE);
+  int encoded_image_size = 0;
+  if (single_nalu) {
+    memcpy(buffer_with_start_code_, start_code, 4);
+    memcpy(buffer_with_start_code_ + 4, input_image._buffer, input_image._length);
+    encoded_image_size = 4 + input_image._length;
+  } else {
+    // need add nalu header
+    memcpy(buffer_with_start_code_, start_code, 4);
+    memcpy(buffer_with_start_code_ + 4, &nalu_header, 1);
+    memcpy(buffer_with_start_code_ + 5, input_image._buffer, input_image._length);
+    encoded_image_size = 5 + input_image._length;
+  }
+  DECODING_STATE rv = decoder_->DecodeFrame2(buffer_with_start_code_, encoded_image_size, (unsigned char**)data, &buffer_info);
+  if (rv != dsErrorFree && !(rv && dsDataErrorConcealed)) {
+    WEBRTC_TRACE(webrtc::kTraceError, webrtc::kTraceVideoCoding, -1,
+                 "H264DecoderImpl::Decode, openH264 decoding fails with error %d, timestamp is %u", rv, input_image._timeStamp);
+    return WEBRTC_VIDEO_CODEC_ERROR;
+  }
+
+  if (buffer_info.iBufferStatus == 1) {
+    int size_y = buffer_info.UsrData.sSystemBuffer.iStride[0] * buffer_info.UsrData.sSystemBuffer.iHeight;
+    int size_u = buffer_info.UsrData.sSystemBuffer.iStride[1] * (buffer_info.UsrData.sSystemBuffer.iHeight/2);
+    int size_v = buffer_info.UsrData.sSystemBuffer.iStride[1] * (buffer_info.UsrData.sSystemBuffer.iHeight/2);
+
+    decoded_image_.CreateFrame(size_y, static_cast<uint8_t*>(data[0]),
+                               size_u, static_cast<uint8_t*>(data[1]),
+                               size_v, static_cast<uint8_t*>(data[2]),
+                               buffer_info.UsrData.sSystemBuffer.iWidth,
+                               buffer_info.UsrData.sSystemBuffer.iHeight,
+                               buffer_info.UsrData.sSystemBuffer.iStride[0],
+                               buffer_info.UsrData.sSystemBuffer.iStride[1],
+                               buffer_info.UsrData.sSystemBuffer.iStride[1]);
+    decoded_image_.set_timestamp(input_image._timeStamp);
+    decode_complete_callback_->Decoded(decoded_image_);
+    return WEBRTC_VIDEO_CODEC_OK;
+  } else {
+    WEBRTC_TRACE(webrtc::kTraceError, webrtc::kTraceVideoCoding, -1,
+                 "H264DecoderImpl::Decode, buffer status:%d, timestamp is %u", buffer_info.iBufferStatus, input_image._timeStamp);
+    return WEBRTC_VIDEO_CODEC_NO_OUTPUT;
+  }
+}
+
+int H264DecoderImpl::RegisterDecodeCompleteCallback(
+    DecodedImageCallback* callback) {
+  decode_complete_callback_ = callback;
+  return WEBRTC_VIDEO_CODEC_OK;
+}
+
+int H264DecoderImpl::Release() {
+  if (last_keyframe_._buffer != NULL) {
+    delete [] last_keyframe_._buffer;
+    last_keyframe_._buffer = NULL;
+  }
+  if (decoder_ != NULL) {
+    decoder_->Uninitialize();
+    WelsDestroyDecoder(decoder_);
+    decoder_ = NULL;
+  }
+  inited_ = false;
+  return WEBRTC_VIDEO_CODEC_OK;
+}
+
+VideoDecoder* H264DecoderImpl::Copy() {
+  // Sanity checks.
+  if (!inited_) {
+    // Not initialized.
+    assert(false);
+    return NULL;
+  }
+  if (decoded_image_.IsZeroSize()) {
+    // Nothing has been decoded before; cannot clone.
+    return NULL;
+  }
+  if (last_keyframe_._buffer == NULL) {
+    // Cannot clone if we have no key frame to start with.
+    return NULL;
+  }
+  // Create a new VideoDecoder object
+  H264DecoderImpl *copy = new H264DecoderImpl;
+
+  // Initialize the new decoder
+  if (copy->InitDecode(&codec_, 1) != WEBRTC_VIDEO_CODEC_OK) {
+    delete copy;
+    return NULL;
+  }
+
+  return static_cast<VideoDecoder*>(copy);
+}
+
+}  // namespace webrtc
diff --git a/src/webrtc/modules/video_coding/codecs/h264/h264_impl.h b/src/webrtc/modules/video_coding/codecs/h264/h264_impl.h
new file mode 100644
index 0000000..ad37282
--- /dev/null
+++ b/src/webrtc/modules/video_coding/codecs/h264/h264_impl.h
@@ -0,0 +1,198 @@
+/*
+ *  Copyright (c) 2012 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ *
+ * WEBRTC H264 wrapper interface
+ */
+
+#ifndef WEBRTC_MODULES_VIDEO_CODING_CODECS_H264_IMPL_H_
+#define WEBRTC_MODULES_VIDEO_CODING_CODECS_H264_IMPL_H_
+
+// OpenH264 headers
+#include "codec_api.h"
+#include "codec_def.h"
+#include "codec_app_def.h"
+
+#include "webrtc/modules/video_coding/codecs/h264/include/h264.h"
+
+namespace webrtc {
+
+class H264EncoderImpl : public H264Encoder {
+ public:
+  H264EncoderImpl();
+
+  virtual ~H264EncoderImpl();
+
+  // Free encoder memory.
+  //
+  // Return value                : WEBRTC_VIDEO_CODEC_OK if OK, < 0 otherwise.
+  virtual int Release();
+
+  // Initialize the encoder with the information from the codecSettings
+  //
+  // Input:
+  //          - codec_settings    : Codec settings
+  //          - number_of_cores   : Number of cores available for the encoder
+  //          - max_payload_size  : The maximum size each payload is allowed
+  //                                to have. Usually MTU - overhead.
+  //
+  // Return value                 : Set bit rate if OK
+  //                                <0 - Errors:
+  //                                  WEBRTC_VIDEO_CODEC_ERR_PARAMETER
+  //                                  WEBRTC_VIDEO_CODEC_ERR_SIZE
+  //                                  WEBRTC_VIDEO_CODEC_LEVEL_EXCEEDED
+  //                                  WEBRTC_VIDEO_CODEC_MEMORY
+  //                                  WEBRTC_VIDEO_CODEC_ERROR
+  virtual int InitEncode(const VideoCodec* codec_settings,
+                         int number_of_cores,
+                         uint32_t max_payload_size);
+
+  // Encode an I420 image (as a part of a video stream). The encoded image
+  // will be returned to the user through the encode complete callback.
+  //
+  // Input:
+  //          - input_image       : Image to be encoded
+  //          - frame_types       : Frame type to be generated by the encoder.
+  //
+  // Return value                 : WEBRTC_VIDEO_CODEC_OK if OK
+  //                                <0 - Errors:
+  //                                  WEBRTC_VIDEO_CODEC_ERR_PARAMETER
+  //                                  WEBRTC_VIDEO_CODEC_MEMORY
+  //                                  WEBRTC_VIDEO_CODEC_ERROR
+  //                                  WEBRTC_VIDEO_CODEC_TIMEOUT
+
+  virtual int Encode(const I420VideoFrame& input_image,
+                     const CodecSpecificInfo* codec_specific_info,
+                     const std::vector<VideoFrameType>* frame_types);
+
+  // Register an encode complete callback object.
+  //
+  // Input:
+  //          - callback         : Callback object which handles encoded images.
+  //
+  // Return value                : WEBRTC_VIDEO_CODEC_OK if OK, < 0 otherwise.
+  virtual int RegisterEncodeCompleteCallback(EncodedImageCallback* callback);
+
+  // Inform the encoder of the new packet loss rate and the round-trip time of
+  // the network.
+  //
+  //          - packet_loss : Fraction lost
+  //                          (loss rate in percent = 100 * packetLoss / 255)
+  //          - rtt         : Round-trip time in milliseconds
+  // Return value           : WEBRTC_VIDEO_CODEC_OK if OK
+  //                          <0 - Errors: WEBRTC_VIDEO_CODEC_ERROR
+  //
+  virtual int SetChannelParameters(uint32_t packet_loss, int rtt);
+
+  // Inform the encoder about the new target bit rate.
+  //
+  //          - new_bitrate_kbit : New target bit rate
+  //          - frame_rate       : The target frame rate
+  //
+  // Return value                : WEBRTC_VIDEO_CODEC_OK if OK, < 0 otherwise.
+  virtual int SetRates(uint32_t new_bitrate_kbit, uint32_t frame_rate);
+
+ private:
+  // Update frame size for codec.
+  int UpdateCodecFrameSize(const I420VideoFrame& input_image);
+
+  //void PopulateCodecSpecific(CodecSpecificInfo* codec_specific,
+  //                           const vpx_codec_cx_pkt& pkt,
+  //                           uint32_t timestamp);
+
+  EncodedImage encoded_image_;
+  EncodedImageCallback* encoded_complete_callback_;
+  VideoCodec codec_;
+  bool inited_;
+  bool first_frame_encoded_;
+  int64_t timestamp_;
+  ISVCEncoder* encoder_;
+};  // end of H264Encoder class
+
+
+class H264DecoderImpl : public H264Decoder {
+ public:
+  enum {
+    //MAX_ENCODED_IMAGE_SIZE = 10240
+	 MAX_ENCODED_IMAGE_SIZE = 102400
+  };
+
+  H264DecoderImpl();
+
+  virtual ~H264DecoderImpl();
+
+  // Initialize the decoder.
+  //
+  // Return value         :  WEBRTC_VIDEO_CODEC_OK.
+  //                        <0 - Errors:
+  //                                  WEBRTC_VIDEO_CODEC_ERROR
+  virtual int InitDecode(const VideoCodec* inst, int number_of_cores);
+
+  // Decode encoded image (as a part of a video stream). The decoded image
+  // will be returned to the user through the decode complete callback.
+  //
+  // Input:
+  //          - input_image         : Encoded image to be decoded
+  //          - missing_frames      : True if one or more frames have been lost
+  //                                  since the previous decode call.
+  //          - fragmentation       : Specifies the start and length of each H264
+  //                                  partition.
+  //          - codec_specific_info : pointer to specific codec data
+  //          - render_time_ms      : Render time in Ms
+  //
+  // Return value                 : WEBRTC_VIDEO_CODEC_OK if OK
+  //                                <0 - Errors:
+  //                                      WEBRTC_VIDEO_CODEC_ERROR
+  //                                      WEBRTC_VIDEO_CODEC_ERR_PARAMETER
+  virtual int Decode(const EncodedImage& input_image,
+                     bool missing_frames,
+                     const RTPFragmentationHeader* fragmentation,
+                     const CodecSpecificInfo* codec_specific_info,
+                     int64_t /*render_time_ms*/);
+
+  // Register a decode complete callback object.
+  //
+  // Input:
+  //          - callback         : Callback object which handles decoded images.
+  //
+  // Return value                : WEBRTC_VIDEO_CODEC_OK if OK, < 0 otherwise.
+  virtual int RegisterDecodeCompleteCallback(DecodedImageCallback* callback);
+
+  // Free decoder memory.
+  //
+  // Return value                : WEBRTC_VIDEO_CODEC_OK if OK
+  //                               <0 - Errors:
+  //                                      WEBRTC_VIDEO_CODEC_ERROR
+  virtual int Release();
+
+  // Reset decoder state and prepare for a new call.
+  //
+  // Return value         : WEBRTC_VIDEO_CODEC_OK.
+  //                        <0 - Errors:
+  //                                  WEBRTC_VIDEO_CODEC_UNINITIALIZED
+  //                                  WEBRTC_VIDEO_CODEC_ERROR
+  virtual int Reset();
+
+  // Create a copy of the codec and its internal state.
+  //
+  // Return value                : A copy of the instance if OK, NULL otherwise.
+  virtual VideoDecoder* Copy();
+
+ private:
+  I420VideoFrame decoded_image_;
+  DecodedImageCallback* decode_complete_callback_;
+  bool inited_;
+  ISVCDecoder* decoder_;
+  VideoCodec codec_;
+  EncodedImage last_keyframe_;
+  bool key_frame_required_;
+  unsigned char* buffer_with_start_code_;
+};  // end of H264Decoder class
+}  // namespace webrtc
+
+#endif  // WEBRTC_MODULES_VIDEO_CODING_CODECS_H264_IMPL_H_
diff --git a/src/webrtc/modules/video_coding/codecs/h264/include/h264.h b/src/webrtc/modules/video_coding/codecs/h264/include/h264.h
new file mode 100644
index 0000000..af10814
--- /dev/null
+++ b/src/webrtc/modules/video_coding/codecs/h264/include/h264.h
@@ -0,0 +1,24 @@
+#ifndef WEBRTC_MODULES_VIDEO_CODING_CODECS_H264_INCLUDE_H264_H_
+#define WEBRTC_MODULES_VIDEO_CODING_CODECS_H264_INCLUDE_H264_H_
+
+#include "webrtc/modules/video_coding/codecs/interface/video_codec_interface.h"
+
+namespace webrtc {
+
+class H264Encoder : public VideoEncoder {
+ public:
+  static H264Encoder* Create();
+
+  virtual ~H264Encoder() {};
+};  // end of H264Encoder class
+
+
+class H264Decoder : public VideoDecoder {
+ public:
+  static H264Decoder* Create();
+
+  virtual ~H264Decoder() {};
+};  // end of H264Decoder class
+}  // namespace webrtc
+
+#endif // WEBRTC_MODULES_VIDEO_CODING_CODECS_H264_INCLUDE_H264_H_
diff --git a/src/webrtc/modules/video_coding/codecs/interface/video_codec_interface.h b/src/webrtc/modules/video_coding/codecs/interface/video_codec_interface.h
index 9776479..3f3baa3 100644
--- a/src/webrtc/modules/video_coding/codecs/interface/video_codec_interface.h
+++ b/src/webrtc/modules/video_coding/codecs/interface/video_codec_interface.h
@@ -47,10 +47,17 @@ struct CodecSpecificInfoGeneric {
   uint8_t simulcast_idx;
 };
 
+struct CodecSpecificInfoH264 {
+  uint8_t nalu_header;
+  bool          single_nalu;
+  uint8_t       simulcastIdx;
+};
+
 union CodecSpecificInfoUnion
 {
     CodecSpecificInfoGeneric   generic;
     CodecSpecificInfoVP8       VP8;
+    CodecSpecificInfoH264      H264;
 };
 
 // Note: if any pointers are added to this struct or its sub-structs, it
diff --git a/src/webrtc/modules/video_coding/main/interface/video_coding_defines.h b/src/webrtc/modules/video_coding/main/interface/video_coding_defines.h
index fab91af..f2edafd 100644
--- a/src/webrtc/modules/video_coding/main/interface/video_coding_defines.h
+++ b/src/webrtc/modules/video_coding/main/interface/video_coding_defines.h
@@ -39,6 +39,7 @@ namespace webrtc {
 #define VCM_RED_PAYLOAD_TYPE        96
 #define VCM_ULPFEC_PAYLOAD_TYPE     97
 #define VCM_VP8_PAYLOAD_TYPE       100
+#define VCM_H264_PAYLOAD_TYPE      101
 #define VCM_I420_PAYLOAD_TYPE      124
 
 enum VCMVideoProtection {
diff --git a/src/webrtc/modules/video_coding/main/source/codec_database.cc b/src/webrtc/modules/video_coding/main/source/codec_database.cc
index 3ff8c76..0931c0a 100644
--- a/src/webrtc/modules/video_coding/main/source/codec_database.cc
+++ b/src/webrtc/modules/video_coding/main/source/codec_database.cc
@@ -19,6 +19,10 @@
 #ifdef VIDEOCODEC_VP8
 #include "webrtc/modules/video_coding/codecs/vp8/include/vp8.h"
 #endif
+#ifdef VIDEOCODEC_H264
+#include "webrtc/modules/video_coding/codecs/h264/include/h264.h"
+#endif
+#include "webrtc/modules/video_coding/main/source/internal_defines.h"
 #include "webrtc/modules/video_coding/main/source/internal_defines.h"
 #include "webrtc/system_wrappers/interface/trace.h"
 
@@ -123,6 +127,26 @@ bool VCMCodecDataBase::Codec(int list_id,
       return true;
     }
 #endif
+#ifdef VIDEOCODEC_H264
+    case VCM_H264_IDX: {
+    	strncpy(settings->plName, "H264", 5);
+    	settings->codecType    = kVideoCodecH264;
+    	// 96 to 127 dynamic payload types for video codecs.
+    	settings->plType       = VCM_H264_PAYLOAD_TYPE;
+    	// Bitrate needed for this size and framerate.
+    	settings->startBitrate = 3 * VCM_DEFAULT_CODEC_WIDTH *
+    			VCM_DEFAULT_CODEC_HEIGHT * 8 *
+    			VCM_DEFAULT_FRAME_RATE / 1000 / 2;
+    	settings->maxBitrate   = settings->startBitrate;
+    	settings->maxFramerate = VCM_DEFAULT_FRAME_RATE;
+    	settings->width        = VCM_DEFAULT_CODEC_WIDTH;
+    	settings->height       = VCM_DEFAULT_CODEC_HEIGHT;
+    	settings->minBitrate   = VCM_MIN_BITRATE;
+    	settings->numberOfSimulcastStreams = 0;
+    	return true;
+    }
+#endif
+
     default: {
       return false;
     }
@@ -343,6 +367,7 @@ bool VCMCodecDataBase::RequiresEncoderReset(const VideoCodec& new_send_codec) {
     case kVideoCodecI420:
     case kVideoCodecRED:
     case kVideoCodecULPFEC:
+    case kVideoCodecH264: // xkd, ffs
       break;
     // Unknown codec type, reset just to be sure.
     case kVideoCodecUnknown:
@@ -610,6 +635,10 @@ VCMGenericEncoder* VCMCodecDataBase::CreateEncoder(
     case kVideoCodecI420:
       return new VCMGenericEncoder(*(new I420Encoder));
 #endif
+#ifdef VIDEOCODEC_H264
+   case kVideoCodecH264:
+      return new VCMGenericEncoder(*(H264Encoder::Create()));
+ #endif
     default:
       return NULL;
   }
@@ -636,6 +665,10 @@ VCMGenericDecoder* VCMCodecDataBase::CreateDecoder(VideoCodecType type) const {
     case kVideoCodecI420:
       return new VCMGenericDecoder(*(new I420Decoder), id_);
 #endif
+#ifdef VIDEOCODEC_H264
+    case kVideoCodecH264:
+      return new VCMGenericDecoder(*(H264Decoder::Create()));
+#endif
     default:
       return NULL;
   }
diff --git a/src/webrtc/modules/video_coding/main/source/decoding_state.cc b/src/webrtc/modules/video_coding/main/source/decoding_state.cc
index aa5e54c..134008e 100644
--- a/src/webrtc/modules/video_coding/main/source/decoding_state.cc
+++ b/src/webrtc/modules/video_coding/main/source/decoding_state.cc
@@ -51,14 +51,14 @@ bool VCMDecodingState::IsOldFrame(const VCMFrameBuffer* frame) const {
   assert(frame != NULL);
   if (in_initial_state_)
     return false;
-  return !IsNewerTimestamp(frame->TimeStamp(), time_stamp_);
+  return !IsNewerOrSameTimestamp(frame->TimeStamp(), time_stamp_);
 }
 
 bool VCMDecodingState::IsOldPacket(const VCMPacket* packet) const {
   assert(packet != NULL);
   if (in_initial_state_)
     return false;
-  return !IsNewerTimestamp(packet->timestamp, time_stamp_);
+  return !IsNewerOrSameTimestamp(packet->timestamp, time_stamp_);
 }
 
 void VCMDecodingState::SetState(const VCMFrameBuffer* frame) {
diff --git a/src/webrtc/modules/video_coding/main/source/encoded_frame.cc b/src/webrtc/modules/video_coding/main/source/encoded_frame.cc
index 6760762..2f46c14 100644
--- a/src/webrtc/modules/video_coding/main/source/encoded_frame.cc
+++ b/src/webrtc/modules/video_coding/main/source/encoded_frame.cc
@@ -136,6 +136,14 @@ void VCMEncodedFrame::CopyCodecSpecific(const RTPVideoHeader* header)
                 }
                 break;
             }
+            case kRtpVideoH264:
+            {
+            	_codecSpecificInfo.codecSpecific.H264.nalu_header         = header->codecHeader.H264.nalu_header;
+            	_codecSpecificInfo.codecSpecific.H264.single_nalu         = header->codecHeader.H264.single_nalu;
+            	_codecSpecificInfo.codecType = kVideoCodecH264;
+            	break;
+            }
+
             default:
             {
                 _codecSpecificInfo.codecType = kVideoCodecUnknown;
diff --git a/src/webrtc/modules/video_coding/main/source/generic_encoder.cc b/src/webrtc/modules/video_coding/main/source/generic_encoder.cc
index 68296fc..9328cc3 100644
--- a/src/webrtc/modules/video_coding/main/source/generic_encoder.cc
+++ b/src/webrtc/modules/video_coding/main/source/generic_encoder.cc
@@ -37,6 +37,10 @@ void CopyCodecSpecific(const CodecSpecificInfo* info, RTPVideoHeader** rtp) {
       (*rtp)->simulcastIdx = info->codecSpecific.VP8.simulcastIdx;
       return;
     }
+    case kVideoCodecH264:
+        (*rtp)->codec = kRtpVideoH264;
+        (*rtp)->simulcastIdx = info->codecSpecific.H264.simulcastIdx;
+       return;
     case kVideoCodecGeneric:
       (*rtp)->codec = kRtpVideoGeneric;
       (*rtp)->simulcastIdx = info->codecSpecific.generic.simulcast_idx;
diff --git a/src/webrtc/modules/video_coding/main/source/internal_defines.h b/src/webrtc/modules/video_coding/main/source/internal_defines.h
index efc6d8d..03d843c 100644
--- a/src/webrtc/modules/video_coding/main/source/internal_defines.h
+++ b/src/webrtc/modules/video_coding/main/source/internal_defines.h
@@ -44,7 +44,13 @@ inline uint32_t MaskWord64ToUWord32(int64_t w64)
 #else
   #define VCM_I420_IDX VCM_VP8_IDX
 #endif
-#define VCM_NUM_VIDEO_CODECS_AVAILABLE VCM_I420_IDX + 1
+#ifdef VIDEOCODEC_H264
+  #define VCM_H264_IDX VCM_I420_IDX + 1
+#else
+  #define VCM_H264_IDX VCM_I420_IDX
+#endif
+#define VCM_NUM_VIDEO_CODECS_AVAILABLE VCM_H264_IDX + 1
+
 
 #define VCM_NO_RECEIVER_ID 0
 
diff --git a/src/webrtc/modules/video_coding/main/source/jitter_buffer.cc b/src/webrtc/modules/video_coding/main/source/jitter_buffer.cc
index f11f81b..8b718ca 100644
--- a/src/webrtc/modules/video_coding/main/source/jitter_buffer.cc
+++ b/src/webrtc/modules/video_coding/main/source/jitter_buffer.cc
@@ -47,8 +47,43 @@ void FrameList::InsertFrame(VCMFrameBuffer* frame) {
   insert(rbegin().base(), FrameListPair(frame->TimeStamp(), frame));
 }
 
-VCMFrameBuffer* FrameList::FindFrame(uint32_t timestamp) const {
+// Find a Frame which (may) include seq_num
+// Note: if we don't have an end for the frame yet AND there are multiple Frames
+// with the same timestamp being input, in theory you can get packets
+// for a later Frame mixed with an earlier one where there's a reordering.
+// e.g. for <frame 1: 1 2 3> <frame 2: 4 5 6> and we receive
+//          1 2 4 3 5 6
+// or       4 1 2 3 5 6
+// we'll return <frame 1> for packet 4, and at some point it needs to move to
+// <frame 2>.  You can't key off isFirstPacket or kNaluStart because the OOO packet
+// may be 5.
+// This can be done by re-characterizing 4 when <frame 1> becomes complete
+// and we find it doesn't include 4.  Perhaps a better abstraction would be
+// to keep the packets in a single sorted list (per timestamp or not,
+// doesn't really matter), and then on insertion look to see if it's in a
+// complete unit (kNaluComplete or kNaluStart ... kNaluEnd sequence), and
+// remove the set *then*.
+//
+// If we instead limit multiple frames with the same timestamp to
+// kNaluComplete (single-packet) frames, it's simpler.  You do need to be
+// careful to pull off Frames only if they're contiguous in sequence number
+// to the previous frame, but that's normal since you can get 4 5 6 1 2 3
+// Note that you have to be careful reordering still:
+// <frame 1: 1> <frame 2: 2 3 4>
+// and arrival 2 1 3 4
+// means you must not match the frame created for 2 when 1 comes in
+VCMFrameBuffer* FrameList::FindFrame(uint16_t seq_num, uint32_t timestamp) const {
   FrameList::const_iterator it = find(timestamp);
+  // TODO(jesup): use seq_num to do the fancier version above, or
+  // rearchitect per above to keep a single list and pull out Frames as they
+  // become complete (or decodable).
+
+  // Simple version: Skip already-complete frames
+  // Note: higher level must deal with the 2 1 3 4 case above by not calling
+  // this for single-nal packets
+  while (it != end() && it->second->GetState() == kStateComplete) {
+       it++;
+  }
   if (it == end())
     return NULL;
   return it->second;
@@ -590,12 +625,22 @@ VCMFrameBufferEnum VCMJitterBuffer::GetFrame(const VCMPacket& packet,
   }
   num_consecutive_old_packets_ = 0;
 
-  *frame = incomplete_frames_.FindFrame(packet.timestamp);
-  if (*frame)
-    return kNoError;
-  *frame = decodable_frames_.FindFrame(packet.timestamp);
-  if (*frame)
-    return kNoError;
+  // Handle the 2 1 3 4 case (where 2 3 4 are frame 2 with the timestamp)
+  // from above, for complete nalu's (single-nalus) only.
+
+  // TODO(jesup) To handle a sequence of fragmented nalus which all are
+  // slices of the same lower-case frame (timestamp), the more complete
+  // solution for FindFrame that uses the seqNum and can move packets
+  // between sessions would be needed.
+
+  if (packet.completeNALU != kNaluComplete) {
+	   *frame = incomplete_frames_.FindFrame(packet.seqNum, packet.timestamp);
+	   if (*frame)
+		   return kNoError;
+	   *frame = decodable_frames_.FindFrame(packet.seqNum, packet.timestamp);
+	   if (*frame && (*frame)->GetState() != kStateComplete)
+		   return kNoError;
+  }
 
   // No match, return empty frame.
   *frame = GetEmptyFrame();
diff --git a/src/webrtc/modules/video_coding/main/source/jitter_buffer.h b/src/webrtc/modules/video_coding/main/source/jitter_buffer.h
index 8586f11..bd7f07c 100644
--- a/src/webrtc/modules/video_coding/main/source/jitter_buffer.h
+++ b/src/webrtc/modules/video_coding/main/source/jitter_buffer.h
@@ -63,7 +63,7 @@ class FrameList
     : public std::map<uint32_t, VCMFrameBuffer*, TimestampLessThan> {
  public:
   void InsertFrame(VCMFrameBuffer* frame);
-  VCMFrameBuffer* FindFrame(uint32_t timestamp) const;
+  VCMFrameBuffer* FindFrame(uint16_t seq_num, uint32_t timestamp) const;
   VCMFrameBuffer* PopFrame(uint32_t timestamp);
   VCMFrameBuffer* Front() const;
   VCMFrameBuffer* Back() const;
diff --git a/src/webrtc/modules/video_coding/main/source/packet.cc b/src/webrtc/modules/video_coding/main/source/packet.cc
index 61ef2ee..f12964c 100644
--- a/src/webrtc/modules/video_coding/main/source/packet.cc
+++ b/src/webrtc/modules/video_coding/main/source/packet.cc
@@ -10,6 +10,7 @@
 
 #include "webrtc/modules/interface/module_common_types.h"
 #include "webrtc/modules/video_coding/main/source/packet.h"
+#include "webrtc/modules/rtp_rtcp/source/rtp_format_h264.h"
 
 #include <assert.h>
 
@@ -111,6 +112,24 @@ void VCMPacket::CopyCodecSpecifics(const RTPVideoHeader& videoHeader)
                 codec = kVideoCodecVP8;
                 break;
             }
+          case kRtpVideoH264:
+          {
+                uint8_t nal_type = videoHeader.codecHeader.H264.nalu_header & RtpFormatH264::kH264NAL_TypeMask;
+                isFirstPacket = videoHeader.isFirstPacket;
+                if (isFirstPacket) {
+                  insertStartCode = true;
+                }
+                if (videoHeader.codecHeader.H264.single_nalu) {
+                   completeNALU = kNaluComplete;
+                } else if (isFirstPacket)
+                   completeNALU = kNaluStart;
+                else if (markerBit)
+                   completeNALU = kNaluEnd;
+                else
+                   completeNALU = kNaluIncomplete;
+                codec = kVideoCodecH264;
+                break;
+          }
         default:
             {
                 codec = kVideoCodecUnknown;
diff --git a/src/webrtc/modules/video_coding/main/source/session_info.cc b/src/webrtc/modules/video_coding/main/source/session_info.cc
index 1cb60d3..4d0a99e 100644
--- a/src/webrtc/modules/video_coding/main/source/session_info.cc
+++ b/src/webrtc/modules/video_coding/main/source/session_info.cc
@@ -11,6 +11,8 @@
 #include "webrtc/modules/video_coding/main/source/session_info.h"
 
 #include "webrtc/modules/video_coding/main/source/packet.h"
+#include "webrtc/modules/rtp_rtcp/source/rtp_format_h264.h"
+#include "webrtc/system_wrappers/interface/logging.h"
 
 namespace webrtc {
 
@@ -136,7 +138,7 @@ int VCMSessionInfo::InsertBuffer(uint8_t* frame_buffer,
 
   ShiftSubsequentPackets(packet_it, packet_size);
 
-  const unsigned char startCode[] = {0, 0, 0, 1};
+  const uint8_t startCode[] = {0, 0, 0, 1};
   if (packet.insertStartCode) {
     memcpy(const_cast<uint8_t*>(packet.dataPtr), startCode,
            kH264StartCodeLengthBytes);
@@ -417,36 +419,65 @@ int VCMSessionInfo::InsertPacket(const VCMPacket& packet,
   if (rit != packets_.rend() &&
       (*rit).seqNum == packet.seqNum && (*rit).sizeBytes > 0)
     return -2;
-
-  // Only insert media packets between first and last packets (when available).
-  // Placing check here, as to properly account for duplicate packets.
-  // Check if this is first packet (only valid for some codecs)
-  // Should only be set for one packet per session.
-  if (packet.isFirstPacket && first_packet_seq_num_ == -1) {
-    // The first packet in a frame signals the frame type.
-    frame_type_ = packet.frameType;
-    // Store the sequence number for the first packet.
-    first_packet_seq_num_ = static_cast<int>(packet.seqNum);
-  } else if (first_packet_seq_num_ != -1 &&
-        !IsNewerSequenceNumber(packet.seqNum, first_packet_seq_num_)) {
-    return -3;
-  } else if (frame_type_ == kFrameEmpty && packet.frameType != kFrameEmpty) {
-    // Update the frame type with the type of the first media packet.
-    // TODO(mikhal): Can this trigger?
-    frame_type_ = packet.frameType;
-  }
-
-  // Track the marker bit, should only be set for one packet per session.
-  if (packet.markerBit && last_packet_seq_num_ == -1) {
-    last_packet_seq_num_ = static_cast<int>(packet.seqNum);
-  } else if (last_packet_seq_num_ != -1 &&
-      IsNewerSequenceNumber(packet.seqNum, last_packet_seq_num_)) {
-    return -3;
+  PacketIterator packet_list_it;
+  if (packet.codec == kVideoCodecH264) {
+	  RTPVideoHeaderH264 h264 = packet.codecSpecificHeader.codecHeader.H264;
+	  uint8_t nal_type = h264.nalu_header & RtpFormatH264::kH264NAL_TypeMask;
+
+	  if (packet.isFirstPacket) {
+		  if (HaveFirstPacket() == false ||
+				  IsNewerSequenceNumber(first_packet_seq_num_, packet.seqNum)) {
+			  first_packet_seq_num_ = packet.seqNum;
+			  frame_type_ = packet.frameType;
+		  }
+	  }
+	  // TODO(jesup) Handle STAP-A's here, since they must share a timestamp.  Break
+	  // into individual packets at this point, then handle like kNaluCompletes
+	  // Ignore Marker bit for reassembly, since it's not 100% guaranteed to be correct
+	  // Look at kNaluComplete (single_nal), or an unbroken sequence of
+	  // isFirstPacket/kNaluStart (FU-A with S bit), FU-A's, FU-A with E bit (kNaluEnd)
+	  if ((packet.completeNALU == kNaluComplete || packet.completeNALU == kNaluEnd) &&
+			  last_packet_seq_num_ == -1) {
+		  last_packet_seq_num_ = static_cast<int>(packet.seqNum);
+	  } else if (last_packet_seq_num_ != -1 &&
+			  IsNewerSequenceNumber(packet.seqNum, last_packet_seq_num_)) {
+		  //LOG(LS_WARNING) << "Received packet with a sequence number which is out"
+		  //                 " of frame boundaries";
+		  return -3;
+	  }
+
+	  // The insert operation invalidates the iterator |rit|.
+	  packet_list_it = packets_.insert(rit.base(), packet);
+  } else {
+	  // Only insert media packets between first and last packets (when available).
+	  // Placing check here, as to properly account for duplicate packets.
+	  // Check if this is first packet (only valid for some codecs)
+	  // Should only be set for one packet per session.
+	  if (packet.isFirstPacket && first_packet_seq_num_ == -1) {
+		  // The first packet in a frame signals the frame type.
+		  frame_type_ = packet.frameType;
+		  // Store the sequence number for the first packet.
+		  first_packet_seq_num_ = static_cast<int>(packet.seqNum);
+	  } else if (first_packet_seq_num_ != -1 &&
+			  !IsNewerSequenceNumber(packet.seqNum, first_packet_seq_num_)) {
+		  return -3;
+	  } else if (frame_type_ == kFrameEmpty && packet.frameType != kFrameEmpty) {
+		  // Update the frame type with the type of the first media packet.
+		  // TODO(mikhal): Can this trigger?
+		  frame_type_ = packet.frameType;
+	  }
+
+	  // Track the marker bit, should only be set for one packet per session.
+	  if (packet.markerBit && last_packet_seq_num_ == -1) {
+		  last_packet_seq_num_ = static_cast<int>(packet.seqNum);
+	  } else if (last_packet_seq_num_ != -1 &&
+			  IsNewerSequenceNumber(packet.seqNum, last_packet_seq_num_)) {
+		  return -3;
+	  }
+
+	  // The insert operation invalidates the iterator |rit|.
+	  packet_list_it = packets_.insert(rit.base(), packet);
   }
-
-  // The insert operation invalidates the iterator |rit|.
-  PacketIterator packet_list_it = packets_.insert(rit.base(), packet);
-
   int returnLength = InsertBuffer(frame_buffer, packet_list_it);
   UpdateCompleteSession();
   if (decode_error_mode == kWithErrors)
diff --git a/src/webrtc/modules/video_coding/main/source/video_coding.gypi b/src/webrtc/modules/video_coding/main/source/video_coding.gypi
index b4f6cb7..0e7ce0c 100644
--- a/src/webrtc/modules/video_coding/main/source/video_coding.gypi
+++ b/src/webrtc/modules/video_coding/main/source/video_coding.gypi
@@ -17,6 +17,7 @@
         '<(webrtc_root)/modules/video_coding/utility/video_coding_utility.gyp:video_coding_utility',
         '<(webrtc_root)/system_wrappers/source/system_wrappers.gyp:system_wrappers',
         '<(webrtc_vp8_dir)/vp8.gyp:webrtc_vp8',
+        '<(webrtc_h264_dir)/h264.gyp:webrtc_h264',        
       ],
       'sources': [
         # interfaces
diff --git a/src/webrtc/modules/video_coding/main/source/video_receiver.cc b/src/webrtc/modules/video_coding/main/source/video_receiver.cc
index a60a6ff..12624a3 100644
--- a/src/webrtc/modules/video_coding/main/source/video_receiver.cc
+++ b/src/webrtc/modules/video_coding/main/source/video_receiver.cc
@@ -59,7 +59,10 @@ VideoReceiver::VideoReceiver(const int32_t id,
       _keyRequestTimer(500, clock_) {
   assert(clock_);
 #ifdef DEBUG_DECODER_BIT_STREAM
-  _bitStreamBeforeDecoder = fopen("decoderBitStream.bit", "wb");
+  char str[12];
+  sprintf(str, "%d", _id);
+  std::string name("decoderBitStream.bit");
+  _bitStreamBeforeDecoder = fopen((name + str).c_str(), "wb");
 #endif
 }
 
diff --git a/src/webrtc/video_engine/vie_codec_impl.cc b/src/webrtc/video_engine/vie_codec_impl.cc
index d2aaab9..e6d2b92 100644
--- a/src/webrtc/video_engine/vie_codec_impl.cc
+++ b/src/webrtc/video_engine/vie_codec_impl.cc
@@ -68,6 +68,24 @@ static void LogCodec(const VideoCodec& codec) {
                    << codec.simulcastStream[idx].qpMax;
 
     }
+  } else if (codec.codecType == kVideoCodecH264) {
+	    LOG(LS_INFO) << "H264 specific settings";
+	    LOG(LS_INFO) << "profile: "
+	                   <<  codec.codecSpecific.H264.profile
+	                   << "constraints: "
+	                   <<  codec.codecSpecific.H264.constraints
+	                   << "level: "
+	                   << codec.codecSpecific.H264.level
+	                   << "packetization mode: "
+	                   << codec.codecSpecific.H264.packetizationMode
+	                   << "framedropping: "
+	                   << codec.codecSpecific.H264.frameDroppingOn
+	                   << "keyFrameInterval: "
+	                   << codec.codecSpecific.H264.keyFrameInterval
+	                   << "spslen: "
+	                   << codec.codecSpecific.H264.spsLen
+	                   << "ppslen: "
+	                   << codec.codecSpecific.H264.ppsLen;
   }
 }
 
