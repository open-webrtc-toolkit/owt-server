Index: src/webrtc/modules/audio_device/include/audio_device_defines.h
===================================================================
--- src/webrtc/modules/audio_device/include/audio_device_defines.h	(revision 7820)
+++ src/webrtc/modules/audio_device/include/audio_device_defines.h	(working copy)
@@ -70,7 +70,8 @@
                                      const uint8_t nChannels,
                                      const uint32_t samplesPerSec,
                                      void* audioSamples,
-                                     uint32_t& nSamplesOut) = 0;
+                                     uint32_t& nSamplesOut,
+                                     const int32_t channelId = -1) = 0;
 
     // Method to pass captured data directly and unmixed to network channels.
     // |channel_ids| contains a list of VoE channels which are the
Index: src/webrtc/modules/audio_conference_mixer/interface/audio_conference_mixer_defines.h
===================================================================
--- src/webrtc/modules/audio_conference_mixer/interface/audio_conference_mixer_defines.h	(revision 7820)
+++ src/webrtc/modules/audio_conference_mixer/interface/audio_conference_mixer_defines.h	(working copy)
@@ -82,6 +82,11 @@
                                const AudioFrame& generalAudioFrame,
                                const AudioFrame** uniqueAudioFrames,
                                const uint32_t size) = 0;
+
+    virtual void NewMixedAudio(const int32_t id,
+                               const AudioFrame& generalAudioFrame,
+                               bool isExlusive,
+                               MixerParticipant* participant) = 0;
 protected:
     AudioMixerOutputReceiver() {}
     virtual ~AudioMixerOutputReceiver() {}
Index: src/webrtc/modules/audio_conference_mixer/source/audio_conference_mixer_impl.cc
===================================================================
--- src/webrtc/modules/audio_conference_mixer/source/audio_conference_mixer_impl.cc	(revision 7820)
+++ src/webrtc/modules/audio_conference_mixer/source/audio_conference_mixer_impl.cc	(working copy)
@@ -280,49 +280,14 @@
     }
 
     // Get an AudioFrame for mixing from the memory pool.
-    AudioFrame* mixedAudio = NULL;
-    if(_audioFramePool->PopMemory(mixedAudio) == -1) {
-        WEBRTC_TRACE(kTraceMemory, kTraceAudioMixerServer, _id,
-                     "failed PopMemory() call");
-        assert(false);
-        return -1;
-    }
-
     bool timeForMixerCallback = false;
-    int retval = 0;
     int32_t audioLevel = 0;
     {
         CriticalSectionScoped cs(_crit.get());
-
-        // TODO(henrike): it might be better to decide the number of channels
-        //                with an API instead of dynamically.
-
-        // Find the max channels over all mixing lists.
-        const int num_mixed_channels = std::max(MaxNumChannels(&mixList),
-            std::max(MaxNumChannels(&additionalFramesList),
-                     MaxNumChannels(&rampOutList)));
-
-        mixedAudio->UpdateFrame(-1, _timeStamp, NULL, 0, _outputFrequency,
-                                AudioFrame::kNormalSpeech,
-                                AudioFrame::kVadPassive, num_mixed_channels);
-
         _timeStamp += _sampleSize;
 
-        MixFromList(*mixedAudio, &mixList);
-        MixAnonomouslyFromList(*mixedAudio, &additionalFramesList);
-        MixAnonomouslyFromList(*mixedAudio, &rampOutList);
+        GenerateMixedFrame(mixList, rampOutList, additionalFramesList, NULL);
 
-        if(mixedAudio->samples_per_channel_ == 0) {
-            // Nothing was mixed, set the audio samples to silence.
-            mixedAudio->samples_per_channel_ = _sampleSize;
-            mixedAudio->Mute();
-        } else {
-            // Only call the limiter if we have something to mix.
-            if(!LimitMixedAudio(*mixedAudio))
-                retval = -1;
-        }
-
-        _mixedAudioLevel.ComputeLevel(mixedAudio->data_,_sampleSize);
         audioLevel = _mixedAudioLevel.GetLevel();
 
         if(_mixerStatusCb) {
@@ -337,14 +302,6 @@
 
     {
         CriticalSectionScoped cs(_cbCrit.get());
-        if(_mixReceiver != NULL) {
-            const AudioFrame** dummy = NULL;
-            _mixReceiver->NewMixedAudio(
-                _id,
-                *mixedAudio,
-                dummy,
-                0);
-        }
 
         if((_mixerStatusCallback != NULL) &&
             timeForMixerCallback) {
@@ -361,8 +318,22 @@
         }
     }
 
+    {
+        CriticalSectionScoped cs(_crit.get());
+        for (std::map<int, MixerParticipant*>::iterator it = mixedParticipantsMap.begin(); it != mixedParticipantsMap.end(); ++it) {
+            int frame_id = it->first;
+            MixerParticipant* participant = it->second;
+            AudioFrameList inList;
+            for (std::list<AudioFrame*>::iterator it2 = mixList.begin(); it2 != mixList.end(); ++it2) {
+                if ((*it2)->id_ != frame_id) {
+                    inList.push_back(*it2);
+                }
+            }
+            GenerateMixedFrame(inList, rampOutList, additionalFramesList, participant);
+        }
+    }
+
     // Reclaim all outstanding memory.
-    _audioFramePool->PushMemory(mixedAudio);
     ClearAudioFrameList(&mixList);
     ClearAudioFrameList(&rampOutList);
     ClearAudioFrameList(&additionalFramesList);
@@ -370,9 +341,69 @@
         CriticalSectionScoped cs(_crit.get());
         _processCalls--;
     }
-    return retval;
+    return 0;
 }
 
+int32_t AudioConferenceMixerImpl::GenerateMixedFrame(
+    AudioFrameList& mixList, 
+    AudioFrameList& rampOutList,                  
+    AudioFrameList& additionalFramesList,
+    MixerParticipant* participant)
+{
+    AudioFrame* mixedAudio = NULL;
+    if(_audioFramePool->PopMemory(mixedAudio) == -1) {
+        WEBRTC_TRACE(kTraceMemory, kTraceAudioMixerServer, _id,
+                     "failed PopMemory() call");
+        assert(false);
+        return -1;
+    }
+
+    int retval = 0;
+    // TODO(henrike): it might be better to decide the number of channels
+    //                with an API instead of dynamically.
+
+    // Find the max channels over all mixing lists.
+    const int num_mixed_channels = std::max(MaxNumChannels(&mixList),
+        std::max(MaxNumChannels(&additionalFramesList),
+                 MaxNumChannels(&rampOutList)));
+
+    mixedAudio->UpdateFrame(-1, _timeStamp, NULL, 0, _outputFrequency,
+                            AudioFrame::kNormalSpeech,
+                            AudioFrame::kVadPassive, num_mixed_channels);
+
+    MixFromList(*mixedAudio, &mixList);
+    MixAnonomouslyFromList(*mixedAudio, &additionalFramesList);
+    MixAnonomouslyFromList(*mixedAudio, &rampOutList);
+
+    if(mixedAudio->samples_per_channel_ == 0) {
+        // Nothing was mixed, set the audio samples to silence.
+        mixedAudio->samples_per_channel_ = _sampleSize;
+        mixedAudio->Mute();
+    } else {
+        // Only call the limiter if we have something to mix.
+        if(!LimitMixedAudio(*mixedAudio))
+            retval = -1;
+    }
+
+    _mixedAudioLevel.ComputeLevel(mixedAudio->data_,_sampleSize);
+
+    {
+        CriticalSectionScoped cs(_cbCrit.get());
+        if(_mixReceiver != NULL) {
+            bool exlusive = (participant != NULL);
+            _mixReceiver->NewMixedAudio(
+                _id,
+                *mixedAudio,
+                exlusive,
+                participant);
+        }
+    }
+
+    // Reclaim all outstanding memory.
+    _audioFramePool->PushMemory(mixedAudio);
+    return retval; 
+}
+
 int32_t AudioConferenceMixerImpl::RegisterMixedStreamCallback(
     AudioMixerOutputReceiver& mixReceiver) {
     CriticalSectionScoped cs(_cbCrit.get());
Index: src/webrtc/modules/audio_conference_mixer/source/audio_conference_mixer_impl.h
===================================================================
--- src/webrtc/modules/audio_conference_mixer/source/audio_conference_mixer_impl.h	(revision 7820)
+++ src/webrtc/modules/audio_conference_mixer/source/audio_conference_mixer_impl.h	(working copy)
@@ -154,6 +154,8 @@
 
     bool LimitMixedAudio(AudioFrame& mixedAudio);
 
+    int32_t GenerateMixedFrame(AudioFrameList& mixList, AudioFrameList& rampOutList,
+                           AudioFrameList& additionalFramesList, MixerParticipant* participant);
     // Scratch memory
     // Note that the scratch memory may only be touched in the scope of
     // Process().
Index: src/webrtc/voice_engine/voe_base_impl.cc
===================================================================
--- src/webrtc/voice_engine/voe_base_impl.cc	(revision 7820)
+++ src/webrtc/voice_engine/voe_base_impl.cc	(working copy)
@@ -148,7 +148,8 @@
         uint8_t nChannels,
         uint32_t samplesPerSec,
         void* audioSamples,
-        uint32_t& nSamplesOut)
+        uint32_t& nSamplesOut,
+        const int32_t channelId)
 {
     WEBRTC_TRACE(kTraceStream, kTraceVoice, VoEId(_shared->instance_id(), -1),
                  "VoEBaseImpl::NeedMorePlayData(nSamples=%u, "
@@ -157,17 +158,21 @@
 
     assert(_shared->output_mixer() != NULL);
 
-    // TODO(andrew): if the device is running in mono, we should tell the mixer
-    // here so that it will only request mono from AudioCodingModule.
-    // Perform mixing of all active participants (channel-based mixing)
-    _shared->output_mixer()->MixActiveChannels();
+    if (channelId == -1) {
+    	// TODO(andrew): if the device is running in mono, we should tell the mixer
+    	// here so that it will only request mono from AudioCodingModule.
+    	// Perform mixing of all active participants (channel-based mixing)
+    	_shared->output_mixer()->MixActiveChannels();
 
-    // Additional operations on the combined signal
-    _shared->output_mixer()->DoOperationsOnCombinedSignal();
+    	// Retrieve the final output mix (resampled to match the ADM)
+    	_shared->output_mixer()->GetMixedAudio(samplesPerSec, nChannels,
+    			&_audioFrame);
 
-    // Retrieve the final output mix (resampled to match the ADM)
-    _shared->output_mixer()->GetMixedAudio(samplesPerSec, nChannels,
-        &_audioFrame);
+    } else {
+    	voe::Channel* channel = _shared->channel_manager().GetChannel(channelId).channel();
+    	_shared->output_mixer()->GetParticipantMixedAudio(samplesPerSec, nChannels,
+    			&_audioFrame, *channel);
+    }
 
     assert(static_cast<int>(nSamples) == _audioFrame.samples_per_channel_);
     assert(samplesPerSec ==
Index: src/webrtc/voice_engine/output_mixer.cc
===================================================================
--- src/webrtc/voice_engine/output_mixer.cc	(revision 7820)
+++ src/webrtc/voice_engine/output_mixer.cc	(working copy)
@@ -35,6 +35,33 @@
     _audioFrame.id_ = id;
 }
 
+void OutputMixer::NewMixedAudio(int32_t id, 
+                                const AudioFrame& generalAudioFrame,
+                                bool isExlusive,
+                                MixerParticipant* participant)
+{
+    WEBRTC_TRACE(kTraceStream, kTraceVoice, VoEId(_instanceId,-1),
+                 "OutputMixer::NewMixedAudio(id=%d)", id);
+
+    _audioFrame.CopyFrom(generalAudioFrame);
+    _audioFrame.id_ = id;
+
+    DoOperationsOnCombinedSignal();
+
+    if (isExlusive) {
+        if (_exclusiveAudioFrames.find(participant) == _exclusiveAudioFrames.end()) {
+            AudioFrame* audioframe = new AudioFrame();
+            ExclusiveAudioFrame frameInfo = {false, audioframe};
+            _exclusiveAudioFrames[participant] = frameInfo;
+        }
+
+        _exclusiveAudioFrames[participant].frame->CopyFrom(_audioFrame);
+        _exclusiveAudioFrames[participant].fresh = true;
+    }
+
+    _inclusiveAudioFrame.CopyFrom(_audioFrame);
+}
+
 void OutputMixer::MixedParticipants(
     int32_t id,
     const ParticipantStatistics* participantStatistics,
@@ -156,6 +183,12 @@
 {
     WEBRTC_TRACE(kTraceMemory, kTraceVoice, VoEId(_instanceId,-1),
                  "OutputMixer::~OutputMixer() - dtor");
+
+    for (std::map<MixerParticipant*, ExclusiveAudioFrame>::iterator it = _exclusiveAudioFrames.begin(); it != _exclusiveAudioFrames.end(); ++it) {
+        delete it->second.frame;
+    }
+    _exclusiveAudioFrames.clear();
+
     if (_externalMedia)
     {
         DeRegisterExternalMediaProcessing();
@@ -509,6 +542,26 @@
     return 0;
 }
 
+int OutputMixer::GetParticipantMixedAudio(int sample_rate_hz, int num_channels,
+                  AudioFrame* audioFrame,
+                  MixerParticipant& participant) {
+	bool isMixed = false;
+	_mixerModule.MixabilityStatus(participant, isMixed);
+
+    std::map<MixerParticipant*, ExclusiveAudioFrame>::iterator it = _exclusiveAudioFrames.find(&participant);
+
+	if (isMixed && it != _exclusiveAudioFrames.end() && it->second.fresh) {
+        AudioFrame* frame = it->second.frame;
+        audioFrame->num_channels_ = num_channels;
+        audioFrame->sample_rate_hz_ = sample_rate_hz;
+        it->second.fresh = false;
+        RemixAndResample(*frame, &resampler_, audioFrame);
+		return 0;
+	}
+
+	return GetMixedAudio(sample_rate_hz, num_channels, audioFrame);
+}
+
 int OutputMixer::GetMixedAudio(int sample_rate_hz,
                                int num_channels,
                                AudioFrame* frame) {
@@ -527,7 +580,7 @@
   frame->sample_rate_hz_ = sample_rate_hz;
   // TODO(andrew): Ideally the downmixing would occur much earlier, in
   // AudioCodingModule.
-  RemixAndResample(_audioFrame, &resampler_, frame);
+  RemixAndResample(_inclusiveAudioFrame, &resampler_, frame);
   return 0;
 }
 
Index: src/webrtc/voice_engine/voe_base_impl.h
===================================================================
--- src/webrtc/voice_engine/voe_base_impl.h	(revision 7820)
+++ src/webrtc/voice_engine/voe_base_impl.h	(working copy)
@@ -89,7 +89,8 @@
                                      uint8_t nChannels,
                                      uint32_t samplesPerSec,
                                      void* audioSamples,
-                                     uint32_t& nSamplesOut);
+                                     uint32_t& nSamplesOut,
+                                     const int32_t channelId = -1);
 
     virtual int OnDataAvailable(const int voe_channels[],
                                 int number_of_voe_channels,
Index: src/webrtc/voice_engine/output_mixer.h
===================================================================
--- src/webrtc/voice_engine/output_mixer.h	(revision 7820)
+++ src/webrtc/voice_engine/output_mixer.h	(working copy)
@@ -70,6 +70,9 @@
 
     int GetMixedAudio(int sample_rate_hz, int num_channels,
                       AudioFrame* audioFrame);
+    int GetParticipantMixedAudio(int sample_rate_hz, int num_channels,
+                      AudioFrame* audioFrame,
+                      MixerParticipant& participant);
 
     // VoEVolumeControl
     int GetSpeechOutputLevel(uint32_t& level);
@@ -97,6 +100,12 @@
         const AudioFrame** uniqueAudioFrames,
         uint32_t size);
 
+    virtual void NewMixedAudio(
+        int32_t id,
+        const AudioFrame& generalAudioFrame,
+        bool isExlusive,
+        MixerParticipant* participant);
+
     // from AudioMixerStatusReceiver
     virtual void MixedParticipants(
         int32_t id,
@@ -145,6 +154,13 @@
     int _mixingFrequencyHz;
     FileRecorder* _outputFileRecorderPtr;
     bool _outputFileRecording;
+
+    struct ExclusiveAudioFrame {
+        bool fresh;
+        AudioFrame* frame;
+    };
+    std::map<MixerParticipant*, ExclusiveAudioFrame> _exclusiveAudioFrames;
+    AudioFrame _inclusiveAudioFrame;
 };
 
 }  // namespace voe
