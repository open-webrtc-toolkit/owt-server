diff --git src/webrtc/modules/audio_conference_mixer/interface/audio_conference_mixer.h src/webrtc/modules/audio_conference_mixer/interface/audio_conference_mixer.h
index 2969ece..da10c8f 100644
--- src/webrtc/modules/audio_conference_mixer/interface/audio_conference_mixer.h
+++ src/webrtc/modules/audio_conference_mixer/interface/audio_conference_mixer.h
@@ -34,7 +34,11 @@ public:
         kLowestPossible   = -1,
         kDefaultFrequency = kWbInHz
     };
-
+    enum Mode
+    {
+    	kInclusive,
+    	kExclusive
+    };
     // Factory method. Constructor disabled.
     static AudioConferenceMixer* Create(int id);
     virtual ~AudioConferenceMixer() {}
@@ -49,6 +53,9 @@ public:
         AudioMixerOutputReceiver& receiver) = 0;
     virtual int32_t UnRegisterMixedStreamCallback() = 0;
 
+    virtual int32_t SetMixingMode(Mode mode) = 0;
+    virtual Mode    MixingMode() = 0;
+
     // Register/unregister a callback class for receiving status information.
     virtual int32_t RegisterMixerStatusCallback(
         AudioMixerStatusReceiver& mixerStatusCallback,
diff --git src/webrtc/modules/audio_conference_mixer/interface/audio_conference_mixer_defines.h src/webrtc/modules/audio_conference_mixer/interface/audio_conference_mixer_defines.h
index 663be18..5af71ee 100644
--- src/webrtc/modules/audio_conference_mixer/interface/audio_conference_mixer_defines.h
+++ src/webrtc/modules/audio_conference_mixer/interface/audio_conference_mixer_defines.h
@@ -15,7 +15,28 @@
 #include "webrtc/typedefs.h"
 
 namespace webrtc {
-class MixHistory;
+// Cheshire cat implementation of MixerParticipant's non virtual functions.
+class MixHistory
+{
+public:
+    MixHistory();
+    ~MixHistory();
+
+    // MixerParticipant function
+    int32_t IsMixed(bool& mixed) const;
+
+    // Sets wasMixed to true if the participant was mixed previous mix
+    // iteration.
+    int32_t WasMixed(bool& wasMixed) const;
+
+    // Updates the mixed status.
+    int32_t SetIsMixed(const bool mixed);
+
+    void ResetMixedStatus();
+private:
+    bool _isMixed;
+};
+
 
 // A callback class that all mixer participants must inherit from/implement.
 class MixerParticipant
@@ -30,11 +51,17 @@ public:
     // mixed will be set to true if the participant was mixed this mix iteration
     int32_t IsMixed(bool& mixed) const;
 
+    void SetSkipped(bool skipped);
+
+    bool IsSkipped() const;
+
     // This function specifies the sampling frequency needed for the AudioFrame
     // for future GetAudioFrame(..) calls.
     virtual int32_t NeededFrequency(const int32_t id) = 0;
 
     MixHistory* _mixHistory;
+    bool _skipped;
+
 protected:
     MixerParticipant();
     virtual ~MixerParticipant();
diff --git src/webrtc/modules/audio_conference_mixer/source/audio_conference_mixer_impl.cc src/webrtc/modules/audio_conference_mixer/source/audio_conference_mixer_impl.cc
index f3883c0..532e831 100644
--- src/webrtc/modules/audio_conference_mixer/source/audio_conference_mixer_impl.cc
+++ src/webrtc/modules/audio_conference_mixer/source/audio_conference_mixer_impl.cc
@@ -66,7 +66,7 @@ void SetParticipantStatistics(ParticipantStatistics* stats,
 }  // namespace
 
 MixerParticipant::MixerParticipant()
-    : _mixHistory(new MixHistory()) {
+    : _mixHistory(new MixHistory()), _skipped(false) {
 }
 
 MixerParticipant::~MixerParticipant() {
@@ -77,6 +77,14 @@ int32_t MixerParticipant::IsMixed(bool& mixed) const {
     return _mixHistory->IsMixed(mixed);
 }
 
+void MixerParticipant::SetSkipped(bool skipped) {
+	_skipped = skipped;
+}
+
+bool MixerParticipant::IsSkipped() const {
+	return _skipped;
+}
+
 MixHistory::MixHistory()
     : _isMixed(0) {
 }
@@ -134,7 +142,8 @@ AudioConferenceMixerImpl::AudioConferenceMixerImpl(int id)
       _timeStamp(0),
       _timeScheduler(kProcessPeriodicityInMs),
       _mixedAudioLevel(),
-      _processCalls(0) {}
+      _processCalls(0),
+      _mode(kInclusive){}
 
 bool AudioConferenceMixerImpl::Init() {
     _crit.reset(CriticalSectionWrapper::CreateCriticalSection());
@@ -183,6 +192,13 @@ bool AudioConferenceMixerImpl::Init() {
 }
 
 AudioConferenceMixerImpl::~AudioConferenceMixerImpl() {
+
+	std::map<MixerParticipant*, AudioFrame*>::iterator it;
+	for (it = _mixedFrames.begin(); it != _mixedFrames.begin(); it++) {
+		if (it->second!=NULL) {
+			_audioFramePool->PushMemory(it->second);
+		}
+	}
     MemoryPool<AudioFrame>::DeleteMemoryPool(_audioFramePool);
     assert(_audioFramePool == NULL);
 }
@@ -273,10 +289,12 @@ int32_t AudioConferenceMixerImpl::Process() {
 
         UpdateToMix(&mixList, &rampOutList, &mixedParticipantsMap,
                     remainingParticipantsAllowedToMix);
+       	GetAdditionalAudio(&additionalFramesList);
+       	if (MixingMode() == kInclusive) {
+       		UpdateMixedStatus(mixedParticipantsMap);
+       		_scratchParticipantsToMixAmount = mixedParticipantsMap.size();
+       	}
 
-        GetAdditionalAudio(&additionalFramesList);
-        UpdateMixedStatus(mixedParticipantsMap);
-        _scratchParticipantsToMixAmount = mixedParticipantsMap.size();
     }
 
     // Get an AudioFrame for mixing from the memory pool.
@@ -306,7 +324,8 @@ int32_t AudioConferenceMixerImpl::Process() {
                                 AudioFrame::kNormalSpeech,
                                 AudioFrame::kVadPassive, num_mixed_channels);
 
-        _timeStamp += _sampleSize;
+        if (MixingMode() == kInclusive)
+        	_timeStamp += _sampleSize;
 
         MixFromList(*mixedAudio, &mixList);
         MixAnonomouslyFromList(*mixedAudio, &additionalFramesList);
@@ -373,6 +392,15 @@ int32_t AudioConferenceMixerImpl::Process() {
     return retval;
 }
 
+int32_t AudioConferenceMixerImpl::SetMixingMode(AudioConferenceMixer::Mode mode) {
+	_mode = mode;
+	return 0;
+}
+
+AudioConferenceMixer::Mode AudioConferenceMixerImpl::MixingMode() {
+	return _mode;
+}
+
 int32_t AudioConferenceMixerImpl::RegisterMixedStreamCallback(
     AudioMixerOutputReceiver& mixReceiver) {
     CriticalSectionScoped cs(_cbCrit.get());
@@ -627,6 +655,10 @@ void AudioConferenceMixerImpl::UpdateToMix(
     for (MixerParticipantList::iterator participant = _participantList.begin();
          participant != _participantList.end();
          ++participant) {
+
+    	if ((*participant)->IsSkipped())
+    		continue;
+
         // Stop keeping track of passive participants if there are already
         // enough participants available (they wont be mixed anyway).
         bool mustAddToPassiveList = (maxAudioFrameCounter >
@@ -645,12 +677,37 @@ void AudioConferenceMixerImpl::UpdateToMix(
         }
         audioFrame->sample_rate_hz_ = _outputFrequency;
 
-        if((*participant)->GetAudioFrame(_id,*audioFrame) != 0) {
-            WEBRTC_TRACE(kTraceWarning, kTraceAudioMixerServer, _id,
-                         "failed to GetAudioFrame() from participant");
-            _audioFramePool->PushMemory(audioFrame);
-            continue;
+        if (MixingMode() == kInclusive) {
+        	if((*participant)->GetAudioFrame(_id,*audioFrame) != 0) {
+        		WEBRTC_TRACE(kTraceWarning, kTraceAudioMixerServer, _id,
+        				"failed to GetAudioFrame() from participant");
+        		_audioFramePool->PushMemory(audioFrame);
+        		continue;
+        	} else {
+        		AudioFrame* cachedAudioFrame = _mixedFrames[*participant];
+        		if (cachedAudioFrame == NULL) {
+        			if(_audioFramePool->PopMemory(cachedAudioFrame) == -1) {
+        				WEBRTC_TRACE(kTraceMemory, kTraceAudioMixerServer, _id,
+        						"failed PopMemory() call");
+        				assert(false);
+        				return;
+        			}
+        			_mixedFrames[*participant] = cachedAudioFrame;
+        		}
+                cachedAudioFrame->CopyFrom(*audioFrame);
+        	}
+        } else {
+        	assert(MixingMode() == kExclusive);
+        	if (_mixedFrames[*participant] != NULL) {
+        		audioFrame->CopyFrom(*_mixedFrames[*participant]);	//GetAudioFrame from cached ones
+        	} else {
+        		WEBRTC_TRACE(kTraceWarning, kTraceAudioMixerServer, _id,
+        				"failed to GetAudioFrame from cached ones");
+
+        	}
+
         }
+
         // TODO(henrike): this assert triggers in some test cases where SRTP is
         // used which prevents NetEQ from making a VAD. Temporarily disable this
         // assert until the problem is fixed on a higher level.
@@ -662,7 +719,7 @@ void AudioConferenceMixerImpl::UpdateToMix(
 
         if(audioFrame->vad_activity_ == AudioFrame::kVadActive) {
             if(!wasMixed) {
-                RampIn(*audioFrame);
+               RampIn(*audioFrame);
             }
 
             if(activeList.size() >= maxAudioFrameCounter) {
@@ -704,6 +761,7 @@ void AudioConferenceMixerImpl::UpdateToMix(
                     assert(mixParticipantList->size() <=
                            kMaximumAmountOfMixedParticipants);
 
+
                     if (replaceWasMixed) {
                       RampOut(*replaceFrame);
                       rampOutList->push_back(replaceFrame);
diff --git src/webrtc/modules/audio_conference_mixer/source/audio_conference_mixer_impl.h src/webrtc/modules/audio_conference_mixer/source/audio_conference_mixer_impl.h
index 31dc71e..b22b2a5 100644
--- src/webrtc/modules/audio_conference_mixer/source/audio_conference_mixer_impl.h
+++ src/webrtc/modules/audio_conference_mixer/source/audio_conference_mixer_impl.h
@@ -28,7 +28,7 @@ class CriticalSectionWrapper;
 
 typedef std::list<AudioFrame*> AudioFrameList;
 typedef std::list<MixerParticipant*> MixerParticipantList;
-
+/*
 // Cheshire cat implementation of MixerParticipant's non virtual functions.
 class MixHistory
 {
@@ -50,7 +50,7 @@ public:
 private:
     bool _isMixed;
 };
-
+*/
 class AudioConferenceMixerImpl : public AudioConferenceMixer
 {
 public:
@@ -85,6 +85,9 @@ public:
         MixerParticipant& participant, const bool mixable);
     virtual int32_t AnonymousMixabilityStatus(
         MixerParticipant& participant, bool& mixable);
+    virtual int32_t SetMixingMode(AudioConferenceMixer::Mode mode);
+    virtual AudioConferenceMixer::Mode    MixingMode();
+
 private:
     enum{DEFAULT_AUDIO_FRAME_POOLSIZE = 50};
 
@@ -207,6 +210,10 @@ private:
 
     // Used for inhibiting saturation in mixing.
     scoped_ptr<AudioProcessing> _limiter;
+
+    AudioConferenceMixer::Mode _mode;
+    // a buffer to store the AudioFrame that has been mixed in previous iteration
+    std::map<MixerParticipant*, AudioFrame*> _mixedFrames;
 };
 }  // namespace webrtc
 
diff --git src/webrtc/modules/audio_device/include/audio_device_defines.h src/webrtc/modules/audio_device/include/audio_device_defines.h
index 9f3e24b..a8742cc 100644
--- src/webrtc/modules/audio_device/include/audio_device_defines.h
+++ src/webrtc/modules/audio_device/include/audio_device_defines.h
@@ -70,7 +70,8 @@ public:
                                      const uint8_t nChannels,
                                      const uint32_t samplesPerSec,
                                      void* audioSamples,
-                                     uint32_t& nSamplesOut) = 0;
+                                     uint32_t& nSamplesOut,
+                                     const int32_t channelId = -1) = 0;
 
     // Method to pass captured data directly and unmixed to network channels.
     // |channel_ids| contains a list of VoE channels which are the
diff --git src/webrtc/modules/video_coding/codecs/h264/h264.gyp src/webrtc/modules/video_coding/codecs/h264/h264.gyp
index ab7ecc7..0d057c1 100644
--- src/webrtc/modules/video_coding/codecs/h264/h264.gyp
+++ src/webrtc/modules/video_coding/codecs/h264/h264.gyp
@@ -25,10 +25,6 @@
       ],
       'include_dirs': [
         '<(openh264_dir)/codec/api/svc',
-        '<(openh264_dir)/codec/common',
-        '<(openh264_dir)/codec/encoder/core/inc',
-        '<(openh264_dir)/codec/encoder/plus/inc',
-        '<(openh264_dir)/codec/processing/interface', 
 		'<(libav_dir)',               
         'include',
         '<(webrtc_root)/common_video/interface',
diff --git src/webrtc/voice_engine/output_mixer.cc src/webrtc/voice_engine/output_mixer.cc
index 1648a9d..fbf3ee6 100644
--- src/webrtc/voice_engine/output_mixer.cc
+++ src/webrtc/voice_engine/output_mixer.cc
@@ -276,6 +276,7 @@ OutputMixer::SetAnonymousMixabilityStatus(MixerParticipant& participant,
 int32_t
 OutputMixer::MixActiveChannels()
 {
+	_mixerModule.SetMixingMode(AudioConferenceMixer::kInclusive);
     return _mixerModule.Process();
 }
 
@@ -509,6 +510,29 @@ int OutputMixer::StopRecordingPlayout()
     return 0;
 }
 
+int OutputMixer::GetParticipantMixedAudio(int sample_rate_hz, int num_channels,
+                  AudioFrame* audioFrame,
+                  MixerParticipant& participant) {
+	bool isMixed = false;
+	_mixerModule.MixabilityStatus(participant, isMixed);
+	if (isMixed == false) {
+		return -1;
+	}
+	participant._mixHistory->IsMixed(isMixed);
+	if (isMixed == false) {
+		return -1;
+	}
+	_mixerModule.SetMixingMode(AudioConferenceMixer::kExclusive);
+	//_mixerModule.SetMixabilityStatus(participant, false);
+	participant.SetSkipped(true);
+	_mixerModule.Process();
+	DoOperationsOnCombinedSignal();
+	//_mixerModule.SetMixabilityStatus(participant, true);
+	participant.SetSkipped(false);
+	return GetMixedAudio(sample_rate_hz, num_channels, audioFrame);
+
+}
+
 int OutputMixer::GetMixedAudio(int sample_rate_hz,
                                int num_channels,
                                AudioFrame* frame) {
diff --git src/webrtc/voice_engine/output_mixer.h src/webrtc/voice_engine/output_mixer.h
index fc9afd8..c60767c 100644
--- src/webrtc/voice_engine/output_mixer.h
+++ src/webrtc/voice_engine/output_mixer.h
@@ -70,6 +70,9 @@ public:
 
     int GetMixedAudio(int sample_rate_hz, int num_channels,
                       AudioFrame* audioFrame);
+    int GetParticipantMixedAudio(int sample_rate_hz, int num_channels,
+                      AudioFrame* audioFrame,
+                      MixerParticipant& participant);
 
     // VoEVolumeControl
     int GetSpeechOutputLevel(uint32_t& level);
diff --git src/webrtc/voice_engine/voe_base_impl.cc src/webrtc/voice_engine/voe_base_impl.cc
index 1b6e144..547f6ac 100644
--- src/webrtc/voice_engine/voe_base_impl.cc
+++ src/webrtc/voice_engine/voe_base_impl.cc
@@ -148,7 +148,8 @@ int32_t VoEBaseImpl::NeedMorePlayData(
         uint8_t nChannels,
         uint32_t samplesPerSec,
         void* audioSamples,
-        uint32_t& nSamplesOut)
+        uint32_t& nSamplesOut,
+        const int32_t channelId)
 {
     WEBRTC_TRACE(kTraceStream, kTraceVoice, VoEId(_shared->instance_id(), -1),
                  "VoEBaseImpl::NeedMorePlayData(nSamples=%u, "
@@ -157,30 +158,45 @@ int32_t VoEBaseImpl::NeedMorePlayData(
 
     assert(_shared->output_mixer() != NULL);
 
-    // TODO(andrew): if the device is running in mono, we should tell the mixer
-    // here so that it will only request mono from AudioCodingModule.
-    // Perform mixing of all active participants (channel-based mixing)
-    _shared->output_mixer()->MixActiveChannels();
+    AudioFrame* resultFrame = NULL;
+    if (channelId == -1) {
+    	// TODO(andrew): if the device is running in mono, we should tell the mixer
+    	// here so that it will only request mono from AudioCodingModule.
+    	// Perform mixing of all active participants (channel-based mixing)
+    	_shared->output_mixer()->MixActiveChannels();
 
-    // Additional operations on the combined signal
-    _shared->output_mixer()->DoOperationsOnCombinedSignal();
+    	// Additional operations on the combined signal
+    	_shared->output_mixer()->DoOperationsOnCombinedSignal();
 
-    // Retrieve the final output mix (resampled to match the ADM)
-    _shared->output_mixer()->GetMixedAudio(samplesPerSec, nChannels,
-        &_audioFrame);
 
-    assert(static_cast<int>(nSamples) == _audioFrame.samples_per_channel_);
+    	// Retrieve the final output mix (resampled to match the ADM)
+    	_shared->output_mixer()->GetMixedAudio(samplesPerSec, nChannels,
+    			&_inclusiveAudioFrame);
+    	resultFrame = &_inclusiveAudioFrame;
+
+    } else {
+    	voe::Channel* channel = _shared->channel_manager().GetChannel(channelId).channel();
+    	if (_shared->output_mixer()->GetParticipantMixedAudio(samplesPerSec, nChannels,
+    			&_exclusiveAudioFrame, *channel) == -1) {
+    		resultFrame = &_inclusiveAudioFrame;
+    	} else {
+    		resultFrame = &_exclusiveAudioFrame;
+    	}
+
+    }
+
+	assert(static_cast<int>(nSamples) == resultFrame->samples_per_channel_);
     assert(samplesPerSec ==
-        static_cast<uint32_t>(_audioFrame.sample_rate_hz_));
+        static_cast<uint32_t>(resultFrame->sample_rate_hz_));
 
     // Deliver audio (PCM) samples to the ADM
     memcpy(
            (int16_t*) audioSamples,
-           (const int16_t*) _audioFrame.data_,
-           sizeof(int16_t) * (_audioFrame.samples_per_channel_
-                   * _audioFrame.num_channels_));
+           (const int16_t*) resultFrame->data_,
+           sizeof(int16_t) * (resultFrame->samples_per_channel_
+                   * resultFrame->num_channels_));
 
-    nSamplesOut = _audioFrame.samples_per_channel_;
+    nSamplesOut = resultFrame->samples_per_channel_;
 
     return 0;
 }
diff --git src/webrtc/voice_engine/voe_base_impl.h src/webrtc/voice_engine/voe_base_impl.h
index df406eb..eaf11cb 100644
--- src/webrtc/voice_engine/voe_base_impl.h
+++ src/webrtc/voice_engine/voe_base_impl.h
@@ -89,7 +89,8 @@ public:
                                      uint8_t nChannels,
                                      uint32_t samplesPerSec,
                                      void* audioSamples,
-                                     uint32_t& nSamplesOut);
+                                     uint32_t& nSamplesOut,
+                                     const int32_t channelId = -1);
 
     virtual int OnDataAvailable(const int voe_channels[],
                                 int number_of_voe_channels,
@@ -154,7 +155,8 @@ private:
     CriticalSectionWrapper& _callbackCritSect;
 
     bool _voiceEngineObserver;
-    AudioFrame _audioFrame;
+    AudioFrame _exclusiveAudioFrame;
+    AudioFrame _inclusiveAudioFrame;
     voe::SharedData* _shared;
 };
 
